We thank the reviewers for their comments, which we feel 
will greatly help improving the presentation of the paper.

Reviewers 2, 3 and 4 ask about mechanisation. We agree that
mechanisation would be a good thing to do. It would be a big
undertaking. Instead, one immediate goal is to provide a symbolic
analysis/model checking tool for our operational semantics to check
invariants up to a bound. Our aim would be to check the two large
examples, TPC-C [47] and RUBiS [41]. Another goal is to provide litmus tests
to demonstrate that implementations (for example, Amazon's 
Dynamo DB) do not satisfy a particular consistency model.


[Are there existing mechanised specifications of abstract executions
that we can hook to?]

Andrea: Not for distributed systems, but there is John's work on transactions on weak 
Memory architecture. He has mechanised specifications for weak memory models 
in Alloy, and uses them to check whether a consistency model 
Allows a dependency graph with an established property. 


Review 1 and 2.

The paper limit is 25 pages plus bibliography, as stipulated in the
submission conditions. However, we agree that having a single application that
illustrates the program analysis in detail would greatly improve the clarity of the paper.
// Andrea: (I think we need to do a bit more for reviewer 1. 
// His concerns are not only about being out of the page limit,
// he clearly wants one application discussed in detail. 
// I think we should say something along the lines)
Andrea: We followed this approach in a former version of the paper, and we are happy to switch back and improve on it. 

We understand that the appendix is long. All details in the appendix
will be in Xiong's thesis, submitted early January, and on
arXiv. Thank you for saying that the appendix contains one (if not
several) papers of its own. Given that our operational semantics for
atomic transactions is an interface between implementations and
clients, and is a reformation of existing axiomatic definitions, we
felt that we had to justify our operational semantics with respect to
all.


Reviewer 3.

....whole history via the versions.......I don't know how to answer this, I've
written down a few notes.....

--[19] records whole history, consistency model given by analysing the
  whole history

--we record the partial key-history. For CC, the ET analyses the
  versions that impact on the transaction, not the whole history. 

--in contrast to [19], our kv-stores focus on client observable history.

--in discussion, Andrea made strong claims that [19] was not good for
  analysing client behaviour. How do we say this?

-- [19] shows that certain definitions of concistency model collapse
to the same thing.  It does not link to implementations or client
behaviour. It will be able to link to implementaitons.  It is probably
difficut for it to provide client anslysis because.....

Andrea: The abstract state in our framework does not keep track of the whole history
but only client-observable history.
For example, it does not contain any information about the order 
of execution of transactions that access disjoint keys, 
which is in contrast with [19] where this information is kept in the state. 
There is evidence that, to enable program reasoning using frameworks that 
carry around the total order in which transactions are executed, 
it is necessary first to infer how transactions interact with each other
in terms of their dependencies (write-read, write-write and read-write relations) [10, 17, 18, 37].  
The nature of what interactions are allowed depends on the consistency model,
and to the best of our knowledge it is not known whether there exists 
an automatic procedure to retrieve it [17]. 
Because our notion of execution test encodes directly 
how transactions are allowed to interact with each others,
our framework does not suffer from the limitation of [19].

Reviewers 2 and 4.

We have considered mechanisation and formal verification before, 
and indeed that is one of the main motivations why we developed our framework.
It has always been our agenda to explore the applicability of our framework 
to bounded model checking and symbolic analysis for client applications,
with potential case studies being TPC-C [47] and RUBiS [41].
As noted by the reviewer, this is a big undertaking, and it would require a paper on his own.

We will work hard to improve the presentation of the paper. We will
act on all detailed comments.

---

// Reviewer 2: 
// (I like Shale/Philippa's answer here, so feel free to ignore this or to merge it with your answer)
// 
// The paper is very long. 
// However, we felt that this is necessary, as it tackles multiple challenges at once
// (e.g. program analysis and protocol verification). 
// We felt that leaving  some of the topics out would have impaired the presentation of the paper. 
// <Follow comments on the Appendix being in Shale's Thesis.>


