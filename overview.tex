\newcommand{\Counter}{\ensuremath{\mathsf{Counter}}}
\newcommand{\ctrinc}{\ensuremath{\mathsf{inc}}}
\newcommand{\ctrread}{\ensuremath{\mathsf{read}}}

\section{Overview}
\label{sec:overview}

\pg{In introduction, we need to introduce the notation kv-store.}

Consider a simple counter object, $\mathsf{Counter}(\ke)$, 
defined over a distributed kv-store.
Clients can manipulate the value of key $\ke$ via two operations, 
$\ctrinc(\ke)$ and $\ctrread(\ke)$:
\[
\begin{array}{r @{\hspace{2pt}} l @{\hspace{18pt}} r @{\hspace{2pt}} l}
\ctrinc(\ke) \eqdef 
&
\begin{session}
\begin{transaction}
\pderef{\pv{x}}{\ke}; \ 
\pmutate{\ke}{\pv{x}+1}
\end{transaction}
\end{session}
&
\ctrread(\ke) \eqdef &
\begin{session}
\begin{transaction}
\pderef{\pv{x}}{\ke}\\
\end{transaction}
\end{session}
\end{array}
\]
Command \( \pderef{\pv{x}}{\ke} \) reads the value of key \( \ke \) to
local variable \( \vx \) and command \( \pmutate{\ke}{\pv{x}+1} \)
writes the value of \( \pv{x}+1 \) to key \( \ke \).  The code of each
operation is wrapped in square brackets, denoting that 
%the enclosed code 
it must be executed \emph{atomically} as a transaction.  
Correctness of atomic transactions is subtle, depending heavily
on implementation details of the distributed kv-store and, in
particular, on its \emph{consistency model}.


\mypar{Consistency Models}
A well-known consistency model is that of \emph{serialisability},
where transactions appear to execute in a sequential (serial) order,
one after another. 
However, implementing serialisability for distributed kv-stores
comes at a significant performance cost. Instead, implementors are content
with \emph{weaker} consistency models, 
that have been implemented both in geo-replicated and sharded databases 
\cite{ramp,rola,cops,wren,redblue,PSI,NMSI,gdur,clocksi,distrsi}.

We motivate these weak consistency models using replicated kv-stores. In
such stores, clients run each operation on an arbitrary replica, and
propagate the effects of the operations (if any) to other
replicas. In this setting, concurrent calls to 
operations can lead to weak behaviours not present with
serialisability.
For instance, consider the program below where clients $\cl_1$ and 
$\cl_2$  run $\ctrinc(\ke)$ concurrently: 
\begin{align}
	\cl_1: \ctrinc(\ke)
	\;\; || \;\;
	\cl_2: \ctrinc(\ke)
	\tag{\textsc{LU}}
	\label{prog:inc2}
\end{align}
Let us assume that  $\ke$ initially holds value $0$.
Intuitively, since transactions are executed atomically, after both
calls to $\ctrinc(\ke)$ have terminated, the counter should hold 
the value $2$.
Indeed, this is the only outcome allowed under serialisability. 
However, when clients execute $\ctrinc(\ke)$ at different replicas,
if the kv-store provides no synchronisation mechanism for transactions,
then it is possible for both clients to read the same initial value $0$ for $\ke$ at their
distinct replicas, update them to $1$, and propagate their updates. Consequently, both
replicas are unchanged with value  $1$ for $\ke$.
%If at Clients performing a 
%$\ctrread(\ke)$ operation will read a final value of $1$ for the counter, 
This weak behaviour is known as the \emph{lost update} anomaly, which
is  allowed under causal consistency \cite{cops,wren,redblue}.
%but not allowed under snapshot
%isolation and serialisability. 

\input{lu-kvstores.tex}
\mypar{Centralised KV-Stores and Views}
Reasoning about programs in a distributed database by capturing the 
whole system state may be cumbersome and error-prone, 
due to the large amount of information that needs to keep tracked. 
Declarative formalisms overcome this issue by abstracting 
from the system state, and relying on the history of operations performed 
by transactions instead.

\pg{Need a start that dovetails with introduction.}
Here we take a different approach, and abstract from 
distribution by projecting the local state of each component 
of the kv-store into a global, \emph{multi-versioned} centralised state; 
that is, we record all versions of each key written, 
together with the meta-data of the transactions that access it. 
Clients then use a mechanism called \emph{client views} to determine 
the subset of versions in the kv-store that are made available to them.
%low-level details of the underlying distributed architecture 
%of the database by modelling kv-stores as global, centralised entities, and 
%employing \emph{multi-versioning} and \emph{client views}. 
%Multi-versioning mandates that we record all versions of each key written, 
%together with the meta-data of the transactions that access it. 
%This yields a history of each key, and may be thought as projecting the local state of each component of the distributed 
%system into a global, centralised state. 
%Client views (or simply views) allow different clients to observe only a subset of the versions available in 
%the kv-store.
%this makes it possible for different clients to 
As such, different clients can observe different states 
of the kv-store, thus allowing for weak behaviours such as the lost update anomaly. 

%\begin{figure*}[h]
%\captionsetup[subfigure]{aboveskip=-5pt, belowskip=5pt}
%\begin{tabular}{@{} c | c | c | c@{}}
%\hline
%\phantom{-}& \phantom{-}& \phantom{-}& \phantom{-}\\
%\begin{subfigure}{0.15\textwidth}
%\begin{centertikz}
%%Location x
%\node(locx) {$\ke \mapsto$};
%
%\matrix(versionx) [version list]
%    at ([xshift=\tikzkvspace]locx.east) {
%    {a} & $\txid_0$ \\
%    {a} & $\emptyset$ \\
%};
%\tikzvalue{versionx-1-1}{versionx-2-1}{locx-v0}{$0$};
%\end{centertikz}\vspace{5pt}%
%\caption{Initial state}
%\label{fig:counter_kv_initial}
%\end{subfigure}
%&
%\begin{subfigure}{0.22\textwidth}
%\begin{centertikz}
%
%%Location x
%\node(locx) {$\ke_1 \mapsto$};
%
%\matrix(versionx) [version list, column 2/.style={text width=6mm}, column 4/.style={text width=6mm}]
%    at ([xshift=\tikzkvspace]locx.east) {
%    {a} & $\txid_0$ & {a} & $\txid$\\
%    {a} & $\left\{\txid \right\}$ & {a} & $\emptyset$ \\
%};
%\tikzvalue{versionx-1-1}{versionx-2-1}{locx-v0}{$0$};
%\tikzvalue{versionx-1-3}{versionx-2-3}{locx-v1}{$1$};
%
%\end{centertikz}\vspace{5pt}
%\caption{After \(\txid \)}
%\label{fig:counter_kv_first_inc}
%\end{subfigure}
%&
%\begin{subfigure}{0.22\textwidth}
%\begin{centertikz}
%
%%Location x
%\node(locx) {$\ke \mapsto$};
%
%\matrix(versionx) [version list, column 2/.style={text width=6mm}, column 3/.style={dotted}, column 4/.style={text width=6mm,dotted}]
%    at ([xshift=\tikzkvspace]locx.east) {
%    {a} & $\txid_0$ & {a} & $\color{gray}\txid$\\
%    {a} & $\left\{\txid \right\}$ & {a} & $\color{gray}\emptyset$ \\
%};
%\tikzvalue{versionx-1-1}{versionx-2-1}{locx-v0}{$0$};
%\node[version node,fit=(versionx-1-3) (versionx-2-3),fill=white,inner sep=0pt,draw=none] (locx-v1) {\color{gray}$1$};
%
%\end{centertikz}\vspace{5pt}
%\caption{View of \( \cl_2 \) before \( \txid' \)}
%\label{fig:counter_kv_view}
%\end{subfigure} 
%&
%\begin{subfigure}{0.30\textwidth}
%\begin{centertikz}
%\node(locx) {$\ke \mapsto$};
%\matrix(versionx) [version list, column 2/.style={text width=10mm}]
%    at ([xshift=\tikzkvspace]locx.east) {
%    {a} & $\txid_0$ & {a} & $\txid$ & {a} & $\txid'$\\
%    {a} & $\{\txid, \txid'\}$ & {a} & $\emptyset$ & {a} & $\emptyset$ \\
%};
%\tikzvalue{versionx-1-1}{versionx-2-1}{locx-v0}{$0$};
%\tikzvalue{versionx-1-3}{versionx-2-3}{locx-v1}{$1$};
%\tikzvalue{versionx-1-5}{versionx-2-5}{locx-v2}{$1$};
%\end{centertikz}%
%\vspace{5pt}
%\caption{After \( \txid' \), lost update}
%\label{fig:counter_kv_final}
%\label{fig:ua-disallowed}
%\end{subfigure}\\
%\hline
%\end{tabular}
%\caption{Example key-value stores (\subref{fig:counter_kv_initial}, \subref{fig:counter_kv_first_inc}, \subref{fig:counter_kv_final}); a client view (\subref{fig:counter_kv_view})}
%\end{figure*}

Let us illustrate how we can produce the lost update anomaly in \eqref{prog:inc2} using our kv-stores. 
The initial kv-store comprises a single key $\ke$, with only one 
version, $(0, \txid_{0}, \emptyset)$, stating that $\ke$ holds value $0$, 
that the version \emph{writer} is the initialising transaction $\txid_0$ (this version was written by $\txid_0$), 
and that the version \emph{reader set} is empty (no transaction has read this version as of yet). 
\Cref{fig:counter_kv_initial} depicts this initial kv-store, with the version
%We represent this key-value store graphically in \cref{fig:counter_kv_initial}. 
%A version is 
represented as a box sub-divided to three sections;
proceeding clockwise from the left, they represent the version value, writer and reader set, respectively.

Suppose that $\cl_1$ first invokes $\ctrinc$ on \cref{fig:counter_kv_initial}. 
In order to mark the versions that $cl_1$ reads and writes while executing the underlying transaction of $\ctrinc$,  
$\cl_1$ first obtains a unique transaction identifier, $\txid$, 
and then proceeds with $\ctrinc(\ke)$. 
It then reads the (only) version of $\ke$ (with value $0$), 
and installs a new value $1$ for $\ke$. 
The resulting kv-store is depicted in \cref{fig:counter_kv_first_inc}.
Note that the initial version of $\ke$ is updated to reflect that it has been read by $\txid$; 
moreover, versions are ordered (left to right), from the oldest to the newest.

Next, client $\cl_2$ invokes $\ctrinc$ on \cref{fig:counter_kv_first_inc}. 
As there are now two versions available for $\ke$, 
we need to determine the version from which $\cl_2$ fetches its value, before running $\ctrinc(\ke)$.
This is where \emph{client views} come into play.
Intuitively, a view of client $\cl_2$ comprises those versions in the kev-store that are \emph{visible} to $\cl_2$, 
\ie those whose values can be read by $\cl_2$. 
If more than one version is visible, then the newest (right-most) such version is selected, 
modelling the \emph{last writer wins} resolution policy used by several kv-stores~\cite{vogels:2009:ec:1435417.1435432}. 
In our example, there are two possible view candidates for $\cl_2$ when running $\ctrinc(\ke)$ on \cref{fig:counter_kv_first_inc}: 
one containing only the initial version of $\ke$, 
another containing both versions of $\ke$.%
\footnote{In fact, if no restrictions on the views are given, there 
are four possible view candidates. 
However, as we explain in \cref{sec:full-semantics}, we always require the view of a client 
to have the initial version of each key marked as visible.}
In the former case, the view is depicted in \cref{fig:counter_kv_view}:
running $\ctrinc(\ke)$ on this view reads $0$ and writes a new version with value $1$, as depicted in \cref{fig:counter_kv_final}.
Such a kv-store does not contain a version with value $2$, despite two increments on $\ke$, producing the lost update anomaly.
In the latter case, running $\ctrinc(\ke)$ reads the latest value ($1$) and writes a new version with value $2$.
%As before, in the former case the resulting kv-store (\cref{fig:counter_kv_final}) does not contain a version with value $2$, despite two increments on $\ke$, producing the lost update anomaly.

\mypar{Execution Tests}
To avoid the lost update anomaly, distributed kv-stores introduce a check at commit time to ensure that 
at most one of concurrent transactions writing to the same key commits. 
This property is known as \emph{write conflict freedom}. 
In our framework, we can simulate this behaviour by introducing the notion of \emph{execution tests}. 
Intuitively, an execution test determines whether a client with a given view can execute a transaction. 
For example, write-conflict freedom can be enforced by requiring that a client commit a transaction writing to $\ke$ 
only if its view contains all versions available in the global state for such a view. 
In our \eqref{prog:inc2} example, this prevents $\cl_2$ from running $\ctrinc(\ke)$ on \cref{fig:counter_kv_first_inc}
if its view only contains the initial version of $\ke$. 
Instead, the $\cl_2$ view must contain both versions of $\ke$, 
thus enforcing $\cl_2$ to install a version with value $2$ after running $\ctrinc(\ke)$
In \cref{sec:program-analysis}, we prove that if the kv-store 
ensures write-conflict freedom as well as few other properties, then clients can increment 
and read from a single counter as if the kv- store were (strictly) serialisable.

However, the situation becomes more complicated if the kv-store contains multiple counters. 
In this case, as each client has its own view on the kv-store, and since the views 
of clients are independent from each other, it is possible for two 
clients to observe the increments on two distinct counters, $\Counter(\ke_1)$ and $\Counter(\ke_2)$, in different orders. 
%This scenario cannot be replicated in a (strictly) serialisable key-value store. 
For instance, consider the following program:
\begin{align}
	\begin{array}[t]{@{} r @{\hspace{2pt}} l || r @{\hspace{2pt}} l || r @{\hspace{2pt}} l @{}}
		\cl_0: 
		& \ctrinc(\ke_1) 
		& \cl_1: 
		& \ctrread(\ke_1)
		& \cl_2: 
		& \ctrread(\ke_1)\\
%
		& \ctrinc(\ke_2) 
		&& \ctrread(\ke_2)
		&& \ctrread(\ke_2)
	\end{array}
	\tag{\textsc{LF}}
	\label{prog:LF}
\end{align}
Suppose that $\cl_0$ executes first and increments $\ke_1$, $\ke_2$. 
Both $\ke_1$ and $\ke_2$ then have two versions with values $0$ and $1$. 
Let us assume that the $\cl_1$ view contains both versions of $\ke_1$, but only 
the initial version of $\ke_2$ (value $0$). 
When next client $\cl_1$ executes, it thus reads $1$ for $\ke_1$ and $0$ for $\ke_2$; 
that is, from the point of view of $\cl_1$, the increment of $\ke_1$ 
happens before the increment of $\ke_2$. 
Conversely, let us assume that the $\cl_2$ view contains both versions for $\ke_2$, but only 
the initial version of $\ke_1$ (value $0$). 
As such, when $\cl_2$ executes , it reads $0$ for $\ke_1$ and $1$ for $\ke_2$;
that is, from the point of view of $\cl_2$, the increment of $\ke_2$ 
happens before the increment of $\ke_1$. 
This behaviour is known as the \emph{long fork} anomaly (\cref{fig:cp-disallowed}). 

The long fork anomaly is disallowed under strong models, \eg SER and 
%snapshot isolation 
SI \cite{fekete-tods}, 
but allowed under weak models \eg PSI  \cite{PSI} and CC. 
\ac{Citations should be moved to the introduction.}
%As such, the execution test for PSI does not need additional constraints/ 
%
%To rule out the long fork anomaly under strong models such as serialisability and SI, 
%we must strengthen the execution test associated with the kv-store.
To capture such consistency models and rule out the long form anomaly as a possible result 
of the program \eqref{prog:LF}, we must strengthen the execution test associated with the kv-store. 
For SER, we strengthen the execution test by requiring that a client can execute a transaction 
only if its view contains all the versions available in the global state. 
For SI, 
%Informally, as we discuss in \cref{sec:cm}, 
the candidate execution test recovers the order in which 
updates of versions have been observed by different clients (\eg $\cl_1$), 
and allows a transaction to commit only if the observations made by the committing client (\eg $\cl_2$) 
are consistent with previous clients (\ie $\cl_1$): we give the formal definition of this execution test 
in \cref{sec:cm}
%In \cref{sec:cm} we give an example of such an execution test, that ensures that the underlying key-value 
%store guarantees the (strong session) snapshot isolation consistency model. 
%For example, 
Under such strengthened execution tests, e.g. the one for SI, in the \eqref{prog:LF} example $\cl_2$ cannot
observe $1$ for $\ke_2$ after observing $0$ for $\ke_1$; 
this is because $\cl_1$ has already established that the increment on $\ke_2$ happens after 
the one of $\ke_1$. 
In \cref{sec:program-analysis}, we prove that if the kv-store consists of multiple counter objects, and the execution test employed by transactions guarantees SI, then the kv-store 
behaves as is it were (strictly) serialisable.
%
As we demonstrate in \cref{sec:cm}, using execution tests on kv-stores, we can specify all well-known consistency models (weak or strong) subject to a few basic conditions. 
%
Moreover, in \cref{sec:verify-impl} we encode two different distributed protocols using kv-stores and views: COPS \cite{cops}, 
a geo-replicated protocol for causal consistency, and Clock-SI \cite{clocksi}, a protocol for SI under partitioned key-value stores.
Each of these protocols is verified against our specifications using execution tests.
