\section{Overview}
\label{sec:overview}

We introduce our centralised operational semantics for describing the
client-observable behaviour of atomic transactions updating  distributed
kv-stores.  We show that our
interleaving semantics provides an ideal mid-point for both verifying
distributed protocols and proving invariant properties of client
programs.


\mypar{Example} We use a simple transactional library, \(\CodeFont{Counter}(\key)\), to
 introduce our operational semantics.  Clients of this counter library can manipulate the
value of key \(\key\) via two transactions:
\( 
\ctrinc(\key) \defeq 
\begin{transaction}
\plookup{\pv{x}}{\key}; \ 
\pmutate{\key}{\pv{x}{+}1}
\end{transaction}
\)
and
\(
\ctrread(\key) \defeq
\begin{transaction}
\plookup{\pv{x}}{\key}
\end{transaction}
\).
The command \( \plookup{\pv{x}}{\key} \) reads the value of key \( \key \) to
local variable \( \vx \), and the command \( \pmutate{\key}{\pv{x}{+}1} \)
writes the value of \( \pv{x}{+}1 \) to key \( \key \).  The code of each
operation is wrapped in square brackets, denoting a transaction that 
must be executed \emph{atomically}.  

Consider a replicated database where a client only interacts with one replica.
For such a database, the behaviour of the atomic transactions is subtle, 
depending heavily on the particular consistency model under consideration.  
Consider the client program defined by:
\[ 
\prog_{\CodeFont{LU}} \defeq \left(\cl_1 : \ctrinc(\key) \;|| \; \cl_2: \ctrinc(\key) \right)
\]
where we assume that the clients \( \cl_1 \) and \( \cl_2 \) work on different replicas and
the \(\key\) initially holds value \(0\) in all replicas.
Intuitively, since transactions are executed atomically, after both
calls to \(\ctrinc(\key)\) have terminated, the counter should hold the value \(2\).
Indeed, this is the only outcome allowed under the consistency model
called {\em serialisability} (\(\SER\)), 
where transactions appear to execute in a sequential (serial) order, one after another.
The implementation of \(\SER\) in distributed kv-stores comes at a
significant performance cost. Therefore, implementers are content with
{weaker} consistency models \cite{tango,CORFU,ramp,rola,cops,wren,redblue,PSI,NMSI,gdur,clocksi,distrsi,PSI-RA,si}. 
For example, if the replicas provide no synchronisation mechanism for transactions,
then it is possible for both clients to read the same initial value \(0\) for \(\key\) at their
distinct replicas, update them to \(1\), and eventually propagate the absolute value of \( \key \) to other replicas. 
Thus, both sites are unchanged with value  \(1\) for \(\key\).
This weak behaviour is known as the \emph{lost update} anomaly, which
is  allowed under  \emph{causal consistency},
but not \emph{parallel snapshot isolation} and \emph{snapshot isolation}.

\input{lu-kvstores.tex}

%%\pg{IMPORTANT: Figure 1e is wrong. The view is given in c not d.}

\mypar{Centralised Operational Semantics}


%\pg{This should be in the introduction or later in (new) section on
  %comparison with execution test, not here: 
%A well-known declarative approach for a range of consistency models
%is to use execution graphs \cite{adya-icde,adya,framework-concur,ev_transactions},
%where nodes are atomic transactions and edges describe the
%known dependencies between transactions. The graphs capture the
%behaviour of the whole program, with different consistency models
%corresponding to different sets of axioms ruling out the invalid graphs. 
%However, execution graphs provide little information about how the 
%state of a kv-store evolves throughout the execution of a program.
%}

Our operational semantics comprises centralised abstract states
 and
execution steps parametrised by an execution test for a particular
consistency model.
% which determines if a client  is
%able to commit a transaction.
An abstract  state is a
centralised, multi-versioned kv-store, which is {\em global} in the
sense that it contains all the versions written by clients, with
client views associated with the  store 
which are {\em partial} in the sense that clients may see different 
subsets of the versions in the kv-store. Each update is given by either
a primitive command which does not affect the kv-store or an atomic
transaction which does affect the store. These atomic
transaction steps are subject to an {\em execution test} which
analyses the state to determine if the update is allowed by 
the associated consistency model. 


We demonstrate that we can reproduce the lost update anomaly given by
\(\prog_{\CodeFont{LU}}\) using our operational semantics.  A
centralised kv-store provides an abstraction of the real-world
replicated key-value store of our example.  It is a function mapping
keys to lists of {versions}.  Each list records {\em all} the values
written to a key together with information about the transactions that
accessed it. The total order of versions on a key $k$ is always known
due to the resolution policy of the distributed database. 
%One widely
%used resolution policy is {\em last-write-wins}. This policy states
%that if two transactions write to the same key, the transaction
%with a greater abstract time should  be ordered after the
%transaction with the smaller abstract time. The time is abstract in
%the sense that the order determined by the resolution policy may not
%agree with the actual physical tme. 
In the \(\prog_{\CodeFont{LU}}\) example, our initial centralised
kv-store comprises a single key \(\key\)  with  one initialisation version \((0, \txid_{0}, \emptyset)\).
This version represents the initialisations in both replicas where \(\key\) holds value \(0\), 
 the version \emph{writer} is the initialising transaction
\(\txid_0\) (this version was written by \(\txid_0\)), 
and  the version \emph{reader set} is empty (no transaction has read this version). 
\Cref{fig:counter_kv_initial} depicts this initial centralised kv-store, with the version
represented as a box sub-divided in three sections: the value \(0\);
the writer \(t_0\); and the reader set \(\emptyset\). 

Suppose that \(\cl_1\) first invokes \(\ctrinc(\key)\) on
\cref{fig:counter_kv_initial}.
%with the (only possible) view given by
%given by the initialisation verision  \((0, \txid_{0}, \emptyset)\).
It does this by choosing a fresh transaction identifier \(\txid\), 
 then reading the initial version
of \(\key\) with value \(0\) 
and writing  a new value \(1\) for \(\key\). 
The resulting kv-store is depicted in \cref{fig:counter_kv_first_inc},
where  the initial version of \(\key\)  has been  updated to reflect that it
has been read by \(\txid\) and a new version with value 1 installed at
the end of the list. 
Now suppose that client \(\cl_2\) invokes \(\ctrinc(\key)\)  on
\cref{fig:counter_kv_first_inc}.  As there are now two versions
available for \(\key\), we must determine the version from which
\(\cl_2\) fetches its value, before running \(\ctrinc(\key)\).  This is
where the partial \emph{client views} come into play.  Intuitively, a view of
client \(\cl_2\) comprises those versions in the kv-store that are
\emph{visible} to \(\cl_2\), \ie those that can be read by
\(\cl_2\).  If more than one version is visible, then the newest
(right-most) version is selected, modelling the \emph{last-write-wins}
resolution policy used by many distributed key-value stores.
In our example, there are two  candidate views for \(\cl_2\) when running
\(\ctrinc(\key)\) on \cref{fig:counter_kv_first_inc}: 
\begin{enumerate*}
\item one containing
only the initial version of \(\key\) as depicted in \cref{fig:counter_kv_view}; and
\item the other containing both versions of \(\key\) as depicted in \cref{fig:counter_kv_view_all}%
\footnote{As we explain in \cref{sec:mkvs-view}, we always require
  the view of a client to include the initial version of each key.}.
\end{enumerate*}
Given the view in \cref{fig:counter_kv_view},
client \(\cl_2\) chooses a fresh
transaction identifier \(t'\), reads the initial value \(0\) and writes a
new version with value \(1\), as depicted in \cref{fig:counter_kv_final}. 
Such a kv-store does not contain a
version with value \(2\), despite two increments on \(\key\), producing
the lost update anomaly. 
Given the view in \cref{fig:counter_kv_view_all},
client \(cl_2\) reads the newest
value \(1\) and writes a new version with value \(2\).


The lost update anomaly is disallowed under consistency models such as
serialisability (\(\SER\)), snapshot isolation (\(\SI\)) and parallel
snapshot isolation (\(\PSI\)).  It is allowed under causal consistency
(\(\CC\)). To remove the behaviour given by the long fork anomaly, we
use an \emph{execution test} which directly restricts the updates that
are possible at the point of the transaction commits.  One simple test
is to enforce a client to commit a transaction writing to \(\key\) if
and only if its view contains {\em all} versions available in the
global state for \(\key\).  This test directly prevents the situation
where the view of $cl_2$ is the one given in \cref{fig:counter_kv_view}. 
It corresponds to what is known in the
literature as \emph{write-conflict freedom} \cite{framework-concur}: the condition
ensures that one concurrent transaction can write to a key at any one
time.


%\pg{This doesn't work, there are too many concepts not defined. I've
  %tried to keep the spirit of what you are doing, but explain it
  %without the  technical jargon. 
%To avoid undesirable behaviour, such as the \emph{lost update} anomaly in \cref{fig:counter_kv_final},
%we use an \emph{execution test} which restricts the possible update at the
%point of the transaction commit.  One such test is to enforce a client
%to commit a transaction writing to \(\key\) if and only if its view
%contains all versions available in the global state for \(\key\),
%captured by the following predicate:
%\[ \textstyle \closed[\kvs,\vi,{\bigcup_{(\mathtt{w},\key,\val) \in \fp}\WWInv[\kvs](\key)}] . \]
%It means a client with a given view \( \vi \) is allowed to commit a transaction to \( \kvs \) 
%if the view is \emph{closed} with respect to a relation 
%\( \rel  = {\bigcup_{(\mathtt{w},\key,\val) \in \fp}\WWInv[\kvs](\key)} \),
%in the sense that:
%if a view \( \vi \) includes a versions written by a transaction \( \txid \), 
%and if there is an edge \( (\txid',\txid) \in \rel \),
%then the view \( \vi \)  must also include versions written by \( \txid' \).
%The \emph{fingerprint} \( \fp \) of a transaction is 
%the read (label \( \mathtt{r} \)) and  write (label \( \mathtt{w} \)) set of the transaction.
%The write-write relation on a key, for example \( (\txid_0,\txid) \in \WW[\kvs](\key) \) in \cref{fig:counter_kv_first_inc},
%means that a transaction \( \txid \) overwrites a version of \( \key \) written by another transaction \( \txid_0 \).
%Note that \( \rel^{-1} \) denotes the reverse of the relation \( \rel \).
%This \( \Pred{closed} \) predicate prevents \(\cl_2\) from running \(\ctrinc(\key)\) on
%\cref{fig:counter_kv_first_inc} if its view only contains the initial
%version of \(\key\).  Instead, the \(\cl_2\) view must contain both
%versions of \(\key\), thus enforcing \(\cl_2\) to write a version with
%value \(2\) after running \(\ctrinc(\key)\). This particular test
%corresponds to \emph{write-conflict freedom}:
%at most one concurrent transaction can write to a key at any one time.}


The situation becomes more complicated when the library contains multiple counters
where each client can read and increment several counters in one session.
For instance, consider the following client:
\[
    \prog_{\CodeFont{LF}} \defeq 
    \begin{multlined}[t]
    \cl_1 : \ptrans{\plookup{\var}{\key_1} ; \pmutate{\key_1}{\var + 1 }} ; 
                \ptrans{\plookup{\var(y)}{\key_2} ; \pmutate{\key_2}{\var(y) + 1} }
        \\ || \ \cl_2: \ptrans{\plookup{\var}{\key_1} ; \plookup{\var(y)}{\key_2} }
                 || \ \cl_3:  \ptrans{\plookup{\var}{\key_1} ; \plookup{\var(y)}{\key_2} } .
    \end{multlined}
\]
For simplicity, we assume that the initial centralised kv-store contains two keys (\cref{fig:overview-sec-long-fork-init}).
Suppose that \(\cl_1\) executes both transactions first,  
updating \(\key_1\) and \(\key_2\) to values \(1\) using
 fresh transaction 
identifiers \( \txid \) and \( \txid' \) respectively. 
This results in \(\key_1\) and \(\key_2\) having two versions with
values \(0\) and \(1\) each, as illustrated in Figure~{1b}. Now 
client \(\cl_2\) executes its transaction, identified by \( \txid_2 \), using a view that 
contains both versions of \(\key_1\) but only the initial version of
\(\key_2\). This means that 
client \(\cl_2\) reads \(1\) for \(\key_1\) and \(0\) for \(\key_2\): that is, 
\(\cl_2\) observes the update of \(\key_1\) happening but not the 
increment of \(\key_2\). 
Finally, \(\cl_3\) executes its transaction, identified by \( \txid_3
\),  using a view that contains both versions for \(\key_2\)
but only the initial version of \(\key_1\). 
This means that 
client \(\cl_3\) reads \(0\) for \(\key_1\) and \(1\) for \(\key_2\):
that is, \(\cl_3\) observes the increment of \(\key_2\) happening
before the  increment of \(\key_1\). 
This is known as the \emph{long fork} anomaly (\cref{fig:overview-sec-long-fork}). 

\input{multi-counter-fig}

The long fork anomaly is disallowed under strong models 
such as serialisability (\(\SER\)) and snapshot isolation (\(\SI\)), 
but is allowed under weaker models such as parallel snapshot isolation (\(\PSI\)), causal consistency (\(\CC\)) and update atomic (\( \UA \)).
To capture such consistency models and rule out the long fork anomaly as a possible result 
of \(\prog_{\CodeFont{LF}}\), we must strengthen the execution test associated with the kv-store.
For \(\SER\), we simply strengthen the execution test by ensuring that a client can execute a transaction 
only if its view contains all versions available in the global state.
For \(\SI\), the execution test is more subtle,  recovering  the order in which 
updates of versions have been observed by different clients:
we strengthen the execution test by ensuring that a client view must contain versions 
that are \emph{close} with respect to their commit order.
This means that if the view \( \vi \) includes a version written by a transaction \( \txid \),
then \( \vi \) must includes all versions written by transactions that committed before \( \txid \).
Our kv-stores do not contain all the information about the commit order.
However, we have enough information to over-approximate the relevant commit order between transactions:
\begin{enumerate*}
\item if a transaction, such as \( \txid_3 \) in \cref{fig:mult-counter},
reads a version written by another transaction \( \txid_0 \),
then \( \txid_3 \) starts after the commit of \( \txid_0 \) (\cref{fig:overview-dependencies-time-line});
\item if a transaction, such as \( \txid \),
writes a newer version of a key \( \key_1 \), 
then \( \txid \) must commit after transactions, such as \( \txidinit \), that write the previous versions of \( \key \) (\cref{fig:overview-dependencies-time-line}); and
\item if a transaction, such as \( \txid_3 \), reads a older version of a \( \key_1 \),
it must start before the commit of any transactions such as \( \txid \) that write the newer versions of \( \key \) (\cref{fig:overview-dependencies-time-line}).
\end{enumerate*}

%\pg{Above: After last sentence, now we need to capture the intuition
  %of how this is done without goign into technical detail. I cfound
  %myself drawing history diagrams to explain, then thought that was
  %too much to explain. It should be two or three sentences. Azalea,
  %please have a go if you can. If you can't, don't worry, Shale is
  %very good at this now. Shale: I will Skype with you this evening at
  %6, and we can sort out then. I am only free from 6-8 at the max
  %(giving up one social event but not the other).} 

%\pg{Again, too much technical information. I've adapted. Please note
  %that t'' does not exist, I think you probably mean t2. The long fork anomaly is disallowed under strong models 
%such as serialisability (\(\SER\)) and snapshot isolation (\(\SI\)), 
%but is allowed under weaker models such as parallel snapshot isolation (\(\PSI\)), causal consistency (\(\CC\)) and update atomic (\( \UA \)).
%To capture such consistency models and rule out the long fork anomaly as a possible result 
%of \(\prog_{\CodeFont{LF}}\), we must strengthen the execution test associated with the kv-store.
%For \(\SER\), we strengthen the execution test by ensuring that a client can execute a transaction 
%only if its view contains all versions available in the global state, 
%captured by the following predicate \( \closed[\kvs,\vi,{\WWInv[\kvs]}]  \),
%which means the view \( \vi \) before commit the transaction must contains all versions in \( \kvs \).
%For \(\SI\), the execution test recovers the order in which 
%updates of versions have been observed by different clients:
%\[
    %\PreClosed(\kvs,\vi,\Trasi(\left( \WR[\kvs] \cup \SO \cup \WW[\kvs] \right)) ; \Refl(\RW[\kvs]) ) 
%\]
%where: 
%\begin{enumerate*} 
%\item write-read dependency relation,
%such as \( (\txid,\txid'') \in \WR[\kvs] \)
%in \cref{fig:overview-sec-long-fork}, states that
%a transaction, \( \txid \), reads a version written by another transaction, \( \txid'' \);
%\item session order, \( \SO \), determines, for each client \( \cl \),
%the commit order of transactions of \( \cl \); and
%\item read-write anti-dependency relation, 
%such as \( (\txid_3,\txid) \in \RW[\kvs] \),
%in \cref{fig:overview-sec-long-fork}, states that
%a transaction, \( \txid_3 \), reads a version that has been overwritten by another transaction, \( \txid \).
%\end{enumerate*} 
%Given this strengthen, client \( \cl_3 \) must
%observe the second version of \( \key_1 \),
%because \( \ToEdge{\txid | \WR[\kvs] -> \txid'' | \RW[\kvs] -> \txid' } \)
%Under such strengthened execution tests for \(\SER \) and \( \SI \), 
%in the \( \prog_{\CodeFont{LF}} \) example,
%\(\cl_2\) cannot observe \(1\) for \(\key_2\) after observing \(0\) for \(\key_1\),
%if \(\cl_1\) has already established that the increment on \(\key_2\) happens after 
%the one of \(\key_1\). 
%%We will give more detail about the formal definitions of many execution tests 
%%for well-known consistency models in \cref{sec:model}.
%}

In \cref{sec:cm}, we formally define the  execution tests and 
associated consistency models on kv-stores and client views. 
\ifTechRepEdits%
In the technical report,
\else%
In \cref{app:et_sound_complete},
\fi
we show the equivalence of our operational definitions of consistency
models and 
the declarative definitions  based on abstract executions \cite{framework-concur},
and hence dependency graphs \cite{adya}. 

\mypar{Comparison with Execution Graphs}

\pg{Maybe something here, maybe somewhere else. I'll understand when
  I've done 1.Also, going to relate to whatever Shale has done on 4.}

\mypar{Verifying Implementation Protocols} 
The first application of our operational
semantics is to show that  implementation protocols  of distributed
key-value stores satisfy certain consistency models. We do this by
faithfully representing the implementation protocol using our centralised
operational semantics: our abstract states provide a faithful abstraction of replicated and partitioned
databases; and our execution tests provide a faithful abstraction of the synchronisation mechanisms 
enforced by these databases when committing a transaction. 
We  verify the correctness of our representation 
using trace refinement. Thus, a distributed protocol
satisfies  the particular consistency model associated with the
particular execution
test of our representation. 
We demonstrate ththat the COPS protocol \citep{cops} for implementing
a replicated database satisfies our definition of causal consistency (%
\ifTechRepEdits%
in \cref{sec:verify-impl} and the technical report%
\else%
\cref{sec:verify-impl,sec:cops}%
\fi%
), and the Clock-SI protocol \citep{clocksi} for implementing a
partitioned database satisfies our definition of snapshot isolation (%
\ifTechRepEdits%
in the technical report%
\else%
\cref{sec:cops}%
\fi%
).  Since our definitions of consistency model are equivalent to those
in the literature, we have demonstrated that COPS and Clock-SI satisfy
the accepted general definitions of consistency model. This contrasts
with 
previous results which showed that these protocols satisfy specific
consistency models  defined for those
particular implementations.

\pg{below: I'm out of time. This paragraph below needs adapting now
  that we have made 5.2 so much stronger. Azalea, please do.} 

\mypar{Proving Invariant Properties of Client Programs} 
The second application of our operational semantics is to prove
invariant properties of client programs (\cref{sec:robustness}).
One property is the robustness for client programs.
A program \(\prog\) is robust if any kv-stores obtained 
by executing \(\prog\) under a weak consistency model can also be obtained under serialisability.
To demonstrate this, we prove the robustness of the single
counter library discussed above against \(\PSI\), 
and the robustness of a multi-counter library and the banking library of \citet{bank-example-wsi}
against \(\SI\).
The latter is done through general conditions on invariant
which guarantees robustness against our new proposed model \( \WSI \),
and hence implies robustness of nay stronger models such as  \( \SI \).
Apart from robustness,
we show that a lock paradigm is correct under \( \UA \), 
although it is not robust.
Thanks to our operational semantics, 
our invariant-based approaches only need to work with single program steps 
rather than whole program traces.
