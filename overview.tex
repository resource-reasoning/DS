\section{Overview}
\label{sec:overview}

We introduce our centralised operational semantics for describing the
client-observable behaviours of atomic transactions updating  distributed
kv-stores.  

\mypar{Example} We use a simple transactional library, \(\CodeFont{Counter}(\key)\), to
 introduce our operational semantics.  Clients of this counter library can manipulate the
value of counter \(\key\) via two transactional operations:
\( 
\ctrinc(\key) \defeq 
\begin{transaction}
\plookup{\pv{x}}{\key}; \ 
\pmutate{\key}{\pv{x}{+}1}
\end{transaction}
\)
and
\(
\ctrread(\key) \defeq
\begin{transaction}
\plookup{\pv{x}}{\key}
\end{transaction}
\).
The \( \plookup{\pv{x}}{\key} \) reads the value of \( \key \) in
local variable \( \vx \); and \( \pmutate{\key}{\pv{x}{+}1} \)
writes \( \pv{x}{+}1 \) to \( \key \).  The code of each
operation is wrapped in square brackets, denoting a transaction that 
executes \emph{atomically}.  

Consider a replicated database where a client only interacts with one replica.
For such a database, the behaviour of the atomic transactions is subtle, 
depending heavily on the particular consistency model under consideration.  
Consider the client program $\prog_{\CodeFont{LU}}$ below:
\[ 
\prog_{\CodeFont{LU}} \defeq \left(\cl_1 : \ctrinc(\key) \;|| \; \cl_2: \ctrinc(\key) \right)
\]
where we assume that clients \( \cl_1 \) and \( \cl_2 \) work on different replicas, and
that \(\key\) initially holds value \(0\) in all replicas.
Intuitively, as transactions are executed atomically, after both
calls to \(\ctrinc(\key)\) have terminated, the counter should hold value \(2\).
Indeed, this is the only outcome allowed under the 
{\em serialisability} (\(\SER\)) consistency model, 
where transactions appear to execute in a sequential order, one after another.
The implementation of \(\SER\) in distributed kv-stores comes at a
significant performance cost. Therefore, implementers are content with
{\em weaker} consistency models \cite{gdur,ramp,CORFU,tango,si,distrsi,clocksi,redblue,rola,cops,PSI-RA,NMSI,PSI,wren}. 
For example, if replicas provide no synchronisation mechanism for transactions,
it is possible for both clients to read the same initial value \(0\) for \(\key\) at their
distinct replicas, update it to \(1\), and eventually propagate their updates of \( \key \) to other replicas. 
Thus, both replicas remain unchanged with value  \(1\) for \(\key\).
This weak behaviour is known as the \emph{lost update} anomaly, which
is allowed under \emph{causal consistency},
but not \emph{parallel snapshot isolation} and \emph{snapshot isolation}.

\input{lu-kvstores.tex}

%%\pg{IMPORTANT: Figure 1e is wrong. The view is given in c not d.}

\mypar{Centralised Operational Semantics}


%\pg{This should be in the introduction or later in (new) section on
  %comparison with execution test, not here: 
%A well-known declarative approach for a range of consistency models
%is to use execution graphs \cite{adya-icde,adya,framework-concur,ev_transactions},
%where nodes are atomic transactions and edges describe the
%known dependencies between transactions. The graphs capture the
%behaviour of the whole program, with different consistency models
%corresponding to different sets of axioms ruling out the invalid graphs. 
%However, execution graphs provide little information about how the 
%state of a kv-store evolves throughout the execution of a program.
%}

Our operational semantics is defined as transitions over centralised \emph{abstract states}, where each transition 
step is parametrised by an \emph{execution test} associated with a particular
consistency model.
% which determines if a client  is
%able to commit a transaction.
An abstract state is a centralised, multi-versioned kv-store, which is {\em global}:
it contains all versions written by all its clients. 
Moreover, each client is associated with a \emph{partial view} allowing it to observe a subset of 
the versions in the kv-store. 
Each transition of our operational semantics is either
a (local) primitive command that updates the kv-store, 
or an atomic transaction which does affect the store. 
These atomic transaction steps are subject to an execution test, which
analyses the state to determine if the associated update is allowed under  
the given consistency model. 


We next show how we produce the lost update anomaly in
\(\prog_{\CodeFont{LU}}\) using our operational semantics.  
A centralised kv-store provides an abstraction of the real-world
replicated key-value store of our example.  It is a function mapping
keys to a {\em version} list, recording {\em all} the values written to the key
together with information about the transactions that
accessed it. The total order of versions on a key $k$ is always known
due to the resolution policy of the distributed database. 
%One widely
%used resolution policy is {\em last-write-wins}. This policy states
%that if two transactions write to the same key, the transaction
%with a greater abstract time should  be ordered after the
%transaction with the smaller abstract time. The time is abstract in
%the sense that the order determined by the resolution policy may not
%agree with the actual physical tme. 
In the \(\prog_{\CodeFont{LU}}\) example, our initial centralised
kv-store comprises a single key \(\key\)  with  one initialisation version \((0, \txid_{0}, \emptyset)\).
This version represents the initialisations in both replicas where \(\key\) holds value \(0\), 
 the version \emph{writer} is the initialising transaction
\(\txid_0\) (this version was written by \(\txid_0\)), 
and  the version \emph{reader set} is empty (no transaction has read this version). 
\Cref{fig:counter_kv_initial} depicts this initial centralised kv-store, with the version
represented as a box sub-divided in three sections: the value \(0\);
the writer \(t_0\); and the reader set \(\emptyset\). 

Suppose that \(\cl_1\) first invokes \(\ctrinc(\key)\) on
\cref{fig:counter_kv_initial}.
%with the (only possible) view given by
%given by the initialisation verision  \((0, \txid_{0}, \emptyset)\).
It does this by choosing a fresh transaction identifier \(\txid\), 
 then reading the initial version
of \(\key\) with value \(0\) 
and writing  a new value \(1\) for \(\key\). 
The resulting kv-store is depicted in \cref{fig:counter_kv_first_inc},
where  the initial version of \(\key\)  has been  updated to reflect that it
has been read by \(\txid\) and a new version with value 1 installed at
the end of the list. 
Now suppose that client \(\cl_2\) invokes \(\ctrinc(\key)\)  on
\cref{fig:counter_kv_first_inc}.  As there are now two versions
available for \(\key\), we must determine the version from which
\(\cl_2\) fetches its value.
%, before running \(\ctrinc(\key)\).  
This is where the partial \emph{client views} come into play.  Intuitively, a view of
client \(\cl_2\) comprises those versions in the kv-store that are
\emph{visible} to \(\cl_2\), \ie those that can be read by
\(\cl_2\).  If more than one version is visible, then the newest
(right-most) version is selected, modelling the \emph{last-write-wins}
resolution policy used by many distributed key-value stores.
In our example, there are two  candidate views for \(\cl_2\) when running
\(\ctrinc(\key)\) on \cref{fig:counter_kv_first_inc}: 
\begin{enumerate*}
\item one containing
only the initial version of \(\key\) as depicted in \cref{fig:counter_kv_view}; and
\item the other containing both versions of \(\key\) as depicted in \cref{fig:counter_kv_view_all}%
\footnote{As we explain in \cref{sec:mkvs-view}, we always require
  the view of a client to include the initial version of each key.}.
\end{enumerate*}
Given the view in \cref{fig:counter_kv_view},
client \(\cl_2\) chooses a fresh
transaction identifier \(t'\), reads the initial value \(0\) and writes a
new version with value \(1\), as depicted in \cref{fig:counter_kv_final}. 
Such a kv-store does not contain a
version with value \(2\), despite two increments on \(\key\), producing
the lost update anomaly. 
Had we used the the view in \cref{fig:counter_kv_view_all} instead,
client \(cl_2\) would have read the newest
value \(1\) and written a new version with value \(2\).


The lost update anomaly is disallowed under consistency models such as
serialisability (\(\SER\)), snapshot isolation (\(\SI\)) and parallel
snapshot isolation (\(\PSI\)).  It is, however, allowed under causal consistency
(\(\CC\)). To disallow the lost update anomaly, we
use an \emph{execution test} which directly restricts the updates that
are possible at the point where the transaction commits.  One simple test
is to enforce a client to commit a transaction writing to \(\key\) if
and only if its view contains {\em all} versions available in the
global state for \(\key\), thus preventing the situation
where the view of $cl_2$ is the one given in \cref{fig:counter_kv_view}. 
This test corresponds to what is known in the 
literature as \emph{write-conflict freedom} \cite{framework-concur}, 
ensuring that at most one concurrent transaction can write to a key at any one time. 


%\pg{This doesn't work, there are too many concepts not defined. I've
  %tried to keep the spirit of what you are doing, but explain it
  %without the  technical jargon. 
%To avoid undesirable behaviour, such as the \emph{lost update} anomaly in \cref{fig:counter_kv_final},
%we use an \emph{execution test} which restricts the possible update at the
%point of the transaction commit.  One such test is to enforce a client
%to commit a transaction writing to \(\key\) if and only if its view
%contains all versions available in the global state for \(\key\),
%captured by the following predicate:
%\[ \textstyle \closed[\kvs,\vi,{\bigcup_{(\mathtt{w},\key,\val) \in \fp}\WWInv[\kvs](\key)}] . \]
%It means a client with a given view \( \vi \) is allowed to commit a transaction to \( \kvs \) 
%if the view is \emph{closed} with respect to a relation 
%\( \rel  = {\bigcup_{(\mathtt{w},\key,\val) \in \fp}\WWInv[\kvs](\key)} \),
%in the sense that:
%if a view \( \vi \) includes a versions written by a transaction \( \txid \), 
%and if there is an edge \( (\txid',\txid) \in \rel \),
%then the view \( \vi \)  must also include versions written by \( \txid' \).
%The \emph{fingerprint} \( \fp \) of a transaction is 
%the read (label \( \mathtt{r} \)) and  write (label \( \mathtt{w} \)) set of the transaction.
%The write-write relation on a key, for example \( (\txid_0,\txid) \in \WW[\kvs](\key) \) in \cref{fig:counter_kv_first_inc},
%means that a transaction \( \txid \) overwrites a version of \( \key \) written by another transaction \( \txid_0 \).
%Note that \( \rel^{-1} \) denotes the reverse of the relation \( \rel \).
%This \( \Pred{closed} \) predicate prevents \(\cl_2\) from running \(\ctrinc(\key)\) on
%\cref{fig:counter_kv_first_inc} if its view only contains the initial
%version of \(\key\).  Instead, the \(\cl_2\) view must contain both
%versions of \(\key\), thus enforcing \(\cl_2\) to write a version with
%value \(2\) after running \(\ctrinc(\key)\). This particular test
%corresponds to \emph{write-conflict freedom}:
%at most one concurrent transaction can write to a key at any one time.}


The situation becomes more complicated when the library contains multiple counters
where each client can read and increment several counters in one session.
For instance, consider the following client:
\[
    \prog_{\CodeFont{LF}} \defeq 
    \begin{multlined}[t]
    \cl_1 : \ptrans{\plookup{\var}{\key_1} ; \pmutate{\key_1}{\var + 1 }} ; 
                \ptrans{\plookup{\var(y)}{\key_2} ; \pmutate{\key_2}{\var(y) + 1} }
        \\ || \ \cl_2: \ptrans{\plookup{\var}{\key_1} ; \plookup{\var(y)}{\key_2} }
                 || \ \cl_3:  \ptrans{\plookup{\var}{\key_1} ; \plookup{\var(y)}{\key_2} } .
    \end{multlined}
\]
For simplicity, we assume that the initial centralised kv-store contains two keys (\cref{fig:overview-sec-long-fork-init}).
Suppose that \(\cl_1\) executes both transactions first,  
writing $1$ to \(\key_1\) and \(\key_2\) using fresh transaction 
identifiers \( \txid \) and \( \txid' \), respectively. 
This results in \(\key_1\) and \(\key_2\) having two versions with
values \(0\) and \(1\) each, as illustrated in \cref{fig:overview-sec-long-fork}. 
Client \(\cl_2\) next executes its transaction, identified by \( \txid_2 \), using a view that 
contains both versions of \(\key_1\) but only the initial version of
\(\key_2\). This means that \(\cl_2\) reads \(1\) for \(\key_1\) and \(0\) for \(\key_2\);
\ie \(\cl_2\) observes the increment of \(\key_1\) happening before that of \(\key_2\). 
Symmetrically, \(\cl_3\) executes its transaction, identified by \( \txid_3
\), using a view that contains both versions for \(\key_2\)
but only the initial version of \(\key_1\). 
%<<<<<<< HEAD
%This means that 
%client \(\cl_3\) reads \(0\) for \(\key_1\) and \(1\) for \(\key_2\):
%that is, \(\cl_3\) observes the increment of \(\key_2\) happening
%before the  increment of \(\key_1\). 
%This is known as the \emph{long fork} anomaly (\cref{fig:overview-sec-long-fork}). 
%=======
As such, \(\cl_3\) reads \(0\) for \(\key_1\) and \(1\) for \(\key_2\);
\ie \(\cl_3\) observes the increment of \(\key_2\) happening before that of  \(\key_1\). 
This behaviour is known as the \emph{long fork} anomaly (\cref{fig:overview-sec-long-fork}). 
%>>>>>>> f9a0e1029272866fad28f842d4eff4dc07f91b39

\input{multi-counter-fig}

The long fork anomaly is disallowed under strong models 
such as serialisability (\(\SER\)) and snapshot isolation (\(\SI\)), 
but is allowed under weaker models such as parallel snapshot isolation (\(\PSI\)), causal consistency (\(\CC\)) and update atomic (\( \UA \)).
To capture such consistency models and disallow the long fork anomaly in
of \(\prog_{\CodeFont{LF}}\), we must strengthen the execution test associated with the kv-store.
For \(\SER\), we simply strengthen the execution test by ensuring that a client can execute a transaction 
only if its view contains all versions available in the global state.
%<<<<<<< HEAD
%=======
%For \(\SI\), the execution test is more subtle, recovering the order in which 
%updates of versions have been observed by different clients. 
%\pg{Above: After last sentence, now we need to capture the intuition
  %of how this is done without going into technical detail. I found
  %myself drawing history diagrams to explain, then thought that was
  %too much to explain. It should be two or three sentences. Azalea,
  %please have a go if you can. If you can't, don't worry, Shale is
  %very good at this now. Shale: I will Skype with you this evening at
  %6, and we can sort out then. I am only free from 6-8 at the max
  %(giving up one social event but not the other).} 
%\pg{Again, too much technical information. I've adapted. Please note
  %that t'' does not exist, I think you probably mean t2. The long fork anomaly is disallowed under strong models 
%such as serialisability (\(\SER\)) and snapshot isolation (\(\SI\)), 
%but is allowed under weaker models such as parallel snapshot isolation (\(\PSI\)), causal consistency (\(\CC\)) and update atomic (\( \UA \)).
%To capture such consistency models and rule out the long fork anomaly as a possible result 
%of \(\prog_{\CodeFont{LF}}\), we must strengthen the execution test associated with the kv-store.
%For \(\SER\), we strengthen the execution test by ensuring that a client can execute a transaction 
%only if its view contains all versions available in the global state, 
%captured by the following predicate \( \closed[\kvs,\vi,{\WWInv[\kvs]}]  \),
%which means the view \( \vi \) before commit the transaction must contains all versions in \( \kvs \).
%For \(\SI\), the execution test recovers the order in which 
%>>>>>>> f9a0e1029272866fad28f842d4eff4dc07f91b39
For \(\SI\), the execution test is more subtle, recovering the order in which 
updates of versions have been observed by different clients:
the execution test ensures that a client view must contain versions 
that are \emph{close} with respect to the commit order of transactions.
This means that if the view \( \vi \) includes a version written by a transaction \( \txid \),
then \( \vi \) must includes all versions written by transactions that committed before \( \txid \).
Our kv-stores do not contain all the information about the commit order.
However, we have enough information to over-approximate the relevant commit order between transactions:
\begin{enumerate*}
\item if a transaction, such as \( \txid_3 \) in \cref{fig:mult-counter},
reads a version written by another transaction \( \txid_0 \),
then \( \txid_3 \) starts after the commit of \( \txid_0 \) (\cref{fig:overview-dependencies-time-line});
\item if a transaction, such as \( \txid \),
writes a newer version of a key \( \key_1 \), 
then \( \txid \) must commit after transactions, such as \( \txidinit \), that write the previous versions of \( \key \) (\cref{fig:overview-dependencies-time-line}); and
\item if a transaction, such as \( \txid_3 \), reads a older version of a \( \key_1 \),
it must start before the commit of any transactions such as \( \txid \) that write the newer versions of \( \key \) (\cref{fig:overview-dependencies-time-line}).
\end{enumerate*}

%\pg{Above: After last sentence, now we need to capture the intuition
  %of how this is done without goign into technical detail. I cfound
  %myself drawing history diagrams to explain, then thought that was
  %too much to explain. It should be two or three sentences. Azalea,
  %please have a go if you can. If you can't, don't worry, Shale is
  %very good at this now. Shale: I will Skype with you this evening at
  %6, and we can sort out then. I am only free from 6-8 at the max
  %(giving up one social event but not the other).} 

%\pg{Again, too much technical information. I've adapted. Please note
  %that t'' does not exist, I think you probably mean t2. The long fork anomaly is disallowed under strong models 
%such as serialisability (\(\SER\)) and snapshot isolation (\(\SI\)), 
%but is allowed under weaker models such as parallel snapshot isolation (\(\PSI\)), causal consistency (\(\CC\)) and update atomic (\( \UA \)).
%To capture such consistency models and rule out the long fork anomaly as a possible result 
%of \(\prog_{\CodeFont{LF}}\), we must strengthen the execution test associated with the kv-store.
%For \(\SER\), we strengthen the execution test by ensuring that a client can execute a transaction 
%only if its view contains all versions available in the global state, 
%captured by the following predicate \( \closed[\kvs,\vi,{\WWInv[\kvs]}]  \),
%which means the view \( \vi \) before commit the transaction must contains all versions in \( \kvs \).
%For \(\SI\), the execution test recovers the order in which 
%updates of versions have been observed by different clients:
%\[
    %\PreClosed(\kvs,\vi,\Trasi(\left( \WR[\kvs] \cup \SO \cup \WW[\kvs] \right)) ; \Refl(\RW[\kvs]) ) 
%\]
%where: 
%\begin{enumerate*} 
%\item write-read dependency relation,
%such as \( (\txid,\txid'') \in \WR[\kvs] \)
%in \cref{fig:overview-sec-long-fork}, states that
%a transaction, \( \txid \), reads a version written by another transaction, \( \txid'' \);
%\item session order, \( \SO \), determines, for each client \( \cl \),
%the commit order of transactions of \( \cl \); and
%\item read-write anti-dependency relation, 
%such as \( (\txid_3,\txid) \in \RW[\kvs] \),
%in \cref{fig:overview-sec-long-fork}, states that
%a transaction, \( \txid_3 \), reads a version that has been overwritten by another transaction, \( \txid \).
%\end{enumerate*} 
%Given this strengthen, client \( \cl_3 \) must
%observe the second version of \( \key_1 \),
%because \( \ToEdge{\txid | \WR[\kvs] -> \txid'' | \RW[\kvs] -> \txid' } \)
%Under such strengthened execution tests for \(\SER \) and \( \SI \), 
%in the \( \prog_{\CodeFont{LF}} \) example,
%\(\cl_2\) cannot observe \(1\) for \(\key_2\) after observing \(0\) for \(\key_1\),
%if \(\cl_1\) has already established that the increment on \(\key_2\) happens after 
%the one of \(\key_1\). 
%%We will give more detail about the formal definitions of many execution tests 
%%for well-known consistency models in \cref{sec:model}.
%}

In \cref{sec:cm}, we formally define the  execution tests and 
associated consistency models on kv-stores and client views. 
\ifTechRepEdits%
In the technical report,
\else%
In \cref{app:et_sound_complete},
\fi
we show the equivalence of our operational definitions of consistency
models and 
the declarative definitions  based on abstract executions \cite{framework-concur},
and hence dependency graphs \cite{adya}. 

%\mypar{Comparison with Execution Graphs}

%\pg{Maybe something here, maybe somewhere else. I'll understand when
  %I've done 1.Also, going to relate to whatever Shale has done on 4.}

\mypar{Verifying Implementation Protocols} 
The first application of our operational
semantics is to show that  implementation protocols  of distributed
key-value stores satisfy certain consistency models. We do this by
faithfully representing the implementation protocol using our centralised
operational semantics: our abstract states provide a faithful abstraction of replicated and partitioned
databases; and our execution tests provide a faithful abstraction of the synchronisation mechanisms 
enforced by these databases when committing a transaction. 
We  verify the correctness of our representation 
using trace refinement. Thus, a distributed protocol
satisfies  the particular consistency model associated with the
particular execution
test of our representation. 
We demonstrate that the COPS protocol \citep{cops} for implementing
a replicated database satisfies our definition of causal consistency (%
\ifTechRepEdits%
in \cref{sec:verify-impl} and the technical report%
\else%
\cref{sec:verify-impl,sec:cops}%
\fi%
), and the Clock-SI protocol \citep{clocksi} for implementing a
partitioned database satisfies our definition of snapshot isolation (%
\ifTechRepEdits%
in the technical report%
\else%
\cref{sec:cops}%
\fi%
).  Since our definitions of consistency model are equivalent to those
in the literature, we have demonstrated that COPS and Clock-SI satisfy
the accepted general definitions of consistency models. This contrasts
with 
previous results which showed that these protocols satisfy specific
consistency models  defined for those
particular implementations.

%\pg{below: I'm out of time. This paragraph below needs adapting now
  %that we have made 5.2 so much stronger. Azalea, please do.
%\azalea{I've had a go below.}  
  %} 

\mypar{Proving Invariant Properties of Client Programs} 
The second application of our operational semantics is to prove
invariant properties of transactional libraries (\cref{sec:robustness}).
One such property is \emph{robustness}.
A library is robust if for all its client programs \(\prog\) and all kv-stores $\kvs$, if $\kvs$ is obtained by executing \(\prog\) under a weak model, then $\kvs$ can also be obtained under the stronger model serialisability.
That is, the library clients have no observable weak behaviours. 

To demonstrate this, we prove the robustness of the single
counter library discussed above against \(\PSI\), 
and the robustness of a multi-counter library and the banking library of \citet{bank-example-wsi}
against \(\SI\).
We do the latter by proving general invariants that guarantee robustness against our new proposed model \( \WSI \) which is weaker than $\SI$; hence our robustness proof against $\WSI$ implies robustness against stronger models such as  \( \SI \).
As we discuss in \cref{sec:robustness}, although existing techniques in the literature can verify such robustness properties, they typically do so by examining \emph{full traces}.
By contrast, we establish invariant properties at each execution step of our operational semantics, thus allowing a simpler, more compositional proof. 


As well as such robustness properties, we further use our operational semantics to prove \emph{library-specific} properties. 
In particular, we show that a lock library is correct under \( \UA \), in that it satisfies the \emph{mutual exclusion guarantee}, 
even though it is not robust.
To do this, we simply encode such library-specific guarantees as invariants of the library, and establish them at each step, as described above. 
By contras, establishing such library-specific properties using the existing techniques is more difficult. 
This is because unlike the kv-stores in our operational semantics, existing techniques do not directly record the library \emph{state}; 
rather, they record full execution traces, making them less amenable for reasoning about such properties.


%
%Thanks to our operational semantics, 
%our invariant-based approaches only need to work with single program steps 
%rather than whole program traces.
