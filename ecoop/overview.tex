\section{Overview}
\label{sec:overview}

We introduce our centralised operational semantics for describing the
client-observable behaviours of atomic transactions updating  distributed
kv-stores. We show that our interleaving semantics provides 
an abstract interface for both verifying distributed protocols 
and proving invariant properties of client programs.

\mypar{Example} We use a simple transactional library, \(\CodeFont{Counter}(\key)\), to
 introduce our operational semantics.  Clients of this counter library can manipulate the
value of counter \(\key\) via two transactional operations:
\( 
\ctrinc(\key) \defeq 
\begin{transaction}
\plookup{\pv{x}}{\key}; \ 
\pmutate{\key}{\pv{x}{+}1}
\end{transaction}
\)
and
\(
\ctrread(\key) \defeq
\begin{transaction}
\plookup{\pv{x}}{\key}
\end{transaction}
\).
The \( \plookup{\pv{x}}{\key} \) reads the value of \( \key \) in
local variable \( \vx \); and \( \pmutate{\key}{\pv{x}{+}1} \)
writes \( \pv{x}{+}1 \) to \( \key \).  The code of each
operation is wrapped in square brackets, denoting a transaction that 
executes \emph{atomically}.  

Consider a replicated database where a client only interacts with one
replica.
For such a database, the behaviour of the atomic transactions is subtle, 
depending heavily on the particular consistency model under consideration.  
Consider the client program $\prog_{\CodeFont{LU}}$ below:

\SpaceAboveMath
\[ 
\prog_{\CodeFont{LU}} \defeq \quad \cl_1 : \ctrinc(\key) \;|| \; \cl_2: \ctrinc(\key) 
\]
\SpaceBelowMath

where we assume that clients \( \cl_1 \) and \( \cl_2 \) work on
different replicas
and, for simplicity,  each replica has a kv-store with just one key $k$. 
Initially, key \(\key\) holds value \(0\) in all replicas.
Intuitively, as transactions are executed atomically, after both
calls to \(\ctrinc(\key)\) have terminated, the counter should hold value \(2\).
Indeed, this is the only outcome allowed under the 
{\em serialisability} (\(\SER\)) consistency model, 
where transactions appear to execute in a sequential order, one after another.
The implementation of \(\SER\) in distributed kv-stores is known to
come at a
significant performance cost. Implementers are, therefore,  content with
{\em weaker} consistency models
\cite{gdur,ramp,CORFU,tango,si,distrsi,clocksi,redblue,rola,cops,PSI-RA,NMSI,PSI,wren}. 
\polish{Less references.}
For example, if replicas provide no synchronisation mechanism for transactions,
it is possible for both clients to read the same initial value \(0\) for \(\key\) at their
distinct replicas, update it to \(1\), and eventually propagate their updates of \( \key \) to other replicas. 
Thus, both replicas remain unchanged with value  \(1\) for \(\key\).
This weak behaviour is known as the \emph{lost update} anomaly, which
is allowed under the \emph{causal consistency} ($\CC$) model,
but not under \emph{parallel snapshot isolation} ($\PSI$) and \emph{snapshot
  isolation} ($\SI$). 

\input{fig-single-counter}

\mypar{Centralised Operational Semantics}
Our operational semantics provides  transitions over 
{abstract states},
comprising 
\begin{enumerate*}
	\item a centralised, multi-versioned {\em kv-store}, which is {\em global} in that  it records all the versions written by all its clients, 
	\item a \emph{client view}, which is {\em partial} in that it records only those versions in the kv-store observed by a client, and 
	\item a variable store local to the client. 
\end{enumerate*}
Each transition of our operational semantics either updates the
variable store using a primitive command, or updates the kv-store using an 
atomic transaction. 
The atomic transactions are subject to an {\em execution test}, which
analyses the state to determine if the associated update is allowed under  
the given consistency model. 


We show how the  lost update anomaly in
\(\prog_{\CodeFont{LU}}\) is represented by   our operational semantics.  
A centralised kv-store provides an abstraction of the real-world
replicated key-value store of our example.  It is a function mapping
keys to a {\em version} list, recording {all} the values written to the key
together with information about the transactions that
accessed it. The total order of versions on a key $k$ is always known
due to the resolution policy of the distributed database. \polish{Does
  it have a name?} 
In the \(\prog_{\CodeFont{LU}}\) example, our initial centralised
kv-store comprises a single key \(\key\)  with  one initialisation version \((0, \txid_{0}, \emptyset)\).
This version represents the initialisations in both replicas where \(\key\) holds value \(0\), 
 the version \emph{writer} is the initialising transaction
\(\txid_0\) (this version was written by \(\txid_0\)), 
and  the version \emph{reader set} is empty (no transaction has read this version). 
\Cref{fig:counter_kv_initial} depicts this initial centralised kv-store, with the version
represented as a box sub-divided in three sections: the value \(0\);
the writer \(t_0\); and the reader set \(\emptyset\). 

Suppose that \(\cl_1\) first invokes \(\ctrinc(\key)\) on
\cref{fig:counter_kv_initial}.
It does this by choosing a fresh transaction identifier \(\txid_1\), 
 then reading the initial version
of \(\key\) with value \(0\) 
and writing  a new value \(1\) for \(\key\). 
The resulting kv-store is depicted in \cref{fig:counter_kv_first_inc},
where  the initial version of \(\key\)  has been  updated to reflect that it
has been read by \(\txid_1 \) and a new version with value 1 is installed at
the end of the list. 
Now suppose that client \(\cl_2\) invokes \(\ctrinc(\key)\)  on
\cref{fig:counter_kv_first_inc}.  
As there are now two versions
available for \(\key\), we must determine the version from which
\(\cl_2\) fetches its value.
This is where the partial \emph{client view} comes into play.  Intuitively, a view of
client \(\cl_2\) comprises those versions in the kv-store that are
\emph{visible} to \(\cl_2\); that is, those that can be read by
\(\cl_2\).  If more than one version is visible, then the newest
(right-most) version is selected, modelling the \emph{last-write-wins}
resolution policy used by many distributed key-value stores.
In our example, there are two  candidate views for \(\cl_2\) when running
\(\ctrinc(\key)\) on \cref{fig:counter_kv_first_inc}: 
one containing
only the initial version of \(\key\) as depicted in \cref{fig:counter_kv_view}; and
the other containing both versions of \(\key\) as depicted in \cref{fig:counter_kv_view_all}%
\footnote{As we explain in \cref{sec:mkvs-view}, we always require
the  client view to include the initial version of each key.}.
Given the \(\cl_2\) view in \cref{fig:counter_kv_view},
client \(\cl_2\) chooses a fresh
transaction identifier \(t_2\), reads the initial value \(0\) and writes a
new version with value \(1\), as depicted in \cref{fig:counter_kv_final}. 
Such a kv-store does not contain a
version with value \(2\), despite two increments on \(\key\), producing
the lost update anomaly. 
Had we used the the \(\cl_2\) view in \cref{fig:counter_kv_view_all} instead,
client \(cl_2\) would have read the newest
value \(1\) and written a new version with value \(2\).

The lost update anomaly is allowed under the \(\CC\) consistency
model, 
and disallowed under 
\(\SER\), \(\SI\) and \(\PSI\).  To distinguish these cases, we
use an \emph{execution test} which directly restricts the updates that
are possible at the point where the transaction commits.  A simple  way of
doing this is to require that a client writing a transaction to
\(\key\) have a view containing  {\em all} versions of  \(\key\)
available in the
global state. This prevents the situation
where the view of $cl_2$ is that  given in \cref{fig:counter_kv_view}. 
This execution test corresponds to what is known in the 
literature as \emph{write-conflict freedom} \cite{framework-concur},
which ensures that at most one concurrent transaction can write to a key at any one time. 

The situation becomes more complicated when the library contains multiple counters
where each client can read and increment several counters in one session.
For instance, consider the following client program:

\SpaceAboveMath
\[
    \prog_{\CodeFont{LF}} \defeq 
    \begin{multlined}[t]
    \cl_1 : \ptrans{\plookup{\var}{\key_1} ; \pmutate{\key_1}{\var + 1 }} ; 
                \ptrans{\plookup{\var(y)}{\key_2} ; \pmutate{\key_2}{\var(y) + 1} }
        \\ || \ \cl_2: \ptrans{\plookup{\var}{\key_1} ; \plookup{\var(y)}{\key_2} }
                 || \ \cl_3:  \ptrans{\plookup{\var}{\key_1} ; \plookup{\var(y)}{\key_2} } .
    \end{multlined}
\]
\SpaceBelowMath[-9pt]

where,  for simplicity,
the  kv-store has just the keys $k_1$ and $k_2$ (\cref{fig:overview-sec-long-fork-init}).
Suppose that \(\cl_1\) executes both transactions first,  
writing $1$ to \(\key_1\) and \(\key_2\) using fresh transaction 
identifiers \( \txid_1 \) and \( \txid'_1 \), respectively. 
This results in \(\key_1\) and \(\key_2\) having two versions with
values \(0\) and \(1\) each, as illustrated in \cref{fig:overview-sec-long-fork}. 
Client \(\cl_2\) next executes its transaction, identified by \( \txid_2 \), using a view that 
contains both versions of \(\key_1\) but only the initial version of
\(\key_2\). This means that \(\cl_2\) reads \(1\) for \(\key_1\) and
\(0\) for \(\key_2\);
that is,  \(\cl_2\) observes the increment of \(\key_1\) happening before that of \(\key_2\). 
Symmetrically, \(\cl_3\) executes its transaction, identified by \( \txid_3
\), using a view that contains both versions for \(\key_2\)
but only the initial version of \(\key_1\). 
As such, \(\cl_3\) reads \(0\) for \(\key_1\) and \(1\) for
\(\key_2\);
that is, \(\cl_3\) observes the increment of \(\key_2\) happening before that of  \(\key_1\). 
This behaviour is known as the \emph{long fork} anomaly (\cref{fig:overview-sec-long-fork}). 

\input{fig-multi-counter}

The long fork anomaly is disallowed under strong models 
such as \(\SER\) and \(\SI\), 
but is allowed under weaker models such as \(\PSI\) and \(\CC\).
To capture such consistency models and disallow the long fork anomaly 
of \(\prog_{\CodeFont{LF}}\), we must strengthen the execution test associated with the kv-store.
For \(\SER\), we simply strengthen the execution test by ensuring that a client can execute a transaction 
only if its view contains all versions available in the global state.
For \(\SI\), the execution test is more subtle, 
%recovering the order in which 
%updates of versions have been observed by different clients. 
%It ensures that 
requiring that a client view be a set of versions 
that is {\em closed} with respect to the commit order of transactions.
This means that if a client view includes a version written by a transaction \( \txid \),
then it must include all versions written by transactions that committed before \( \txid \).
Our kv-stores do not contain all the information about the commit order.
\polish{I'm not sure about the next sentence, how is it
  over-approximating?} 
However, we have enough information to over-approximate the relevant commit order between transactions:
\begin{enumerate*}
	\item if a transaction, \eg \( \txid_3 \) in \cref{fig:mult-counter},
reads a version written by another transaction, \eg \( \txid_0 \),
then it must start after the commit of the transaction that
wrote the version, \eg \( \txid_3 \) must start after the commit of  \( \txid_0 \)
(\cref{fig:overview-dependencies-time-line}); \polish{And $\txid_1$ must be
  after the commit of $\txid_0$, figure needs changing};
	\item if a transaction writes a newer version of a key, \eg \( \txid_1 \) for \( \key_1 \), 
then  it must commit after the transactions that wrote the previous versions of the key,\eg \( \txidinit \)  (\cref{fig:overview-dependencies-time-line}); and
	\item if a transaction reads an older version of a key, \eg \( \txid_3 \) for \( \key_1 \),
it must start before the commit of all transactions that write the newer versions of \( \key \), \eg \(
\txid_1 \) (\cref{fig:overview-dependencies-time-line}).
\end{enumerate*}

In \cref{sec:cm}, we formally define the execution tests associated with several consistency models on kv-stores and client views. 
In \cite{shale-phd}, we show the equivalence of our operational definitions of consistency
models and the existing declarative definitions based on abstract executions \cite{framework-concur},
and hence those based on dependency graphs \cite{adya}. 

\mypar{Verifying Implementation Protocols} 
The first application of our operational
semantics is to show that  implementation protocols  of distributed
key-value stores satisfy certain consistency models. We do this by
faithfully representing the implementation protocol using our centralised
operational semantics: our abstract states provide a faithful abstraction of replicated and partitioned
databases, and our execution tests provide a faithful abstraction of the synchronisation mechanisms 
enforced by these databases when committing a transaction. 
We verify the correctness of our representation 
using trace refinement. Thus, a distributed protocol
satisfies the particular consistency model associated with the
particular execution
test of our representation. 
We demonstrate that the COPS protocol \citep{cops} for implementing
a replicated database satisfies our definition of $\CC$
(reported in \cref{sec:verify-impl} and proved in \cite{shale-phd}), 
and the Clock-SI protocol \citep{clocksi} for implementing a
partitioned database satisfies our definition of $\SI$
(given in \cite{shale-phd}). Since our definitions of consistency model are equivalent to those
in the literature \cite{shale-phd}, we have demonstrated that COPS and Clock-SI satisfy
the accepted general definitions of the respective consistency models. This contrasts
with the previous results in~\citep{cops} and~\citep{clocksi} which
demonstrated that these protocols satisfy specific consistency models defined for those particular implementations.

\mypar{Proving Invariant Properties of Client Programs} 
The second application of our operational semantics is to prove
invariant properties for transactional libraries (\cref{sec:robustness}).
One well-known  property is \emph{robustness}.
A library is robust if,  for all its client programs \(\prog\) and all kv-stores $\kvs$, 
if $\kvs$ is obtained by executing \(\prog\) under a weak consistency
model, then $\kvs$ can also be obtained under \(\SER\);
that is, the library clients have no observable weak behaviours. 
We prove the robustness of the single
counter library against \(\PSI\), 
and the robustness of a multi-counter library and the  banking library of \citet{bank-example-wsi}
against \(\SI\).
We prove  the robustness results against \(\SI\)
by proving general invariants that guarantee robustness against  a
new model we propose, \( \WSI \), which lies between \(\PSI\)
and  $\SI$. 
As we discuss in \cref{sec:robustness}, although existing techniques in the literature can verify such robustness properties, they typically do so by examining \emph{full traces}.
By contrast, we establish invariant properties at each execution step of our operational semantics, thus allowing a simpler, more compositional proof. 


We also demonstrate the use of  our operational semantics to prove
{library-specific} invariant properties. 
In particular, we show that a lock library is correct against \( \PSI \), in that it satisfies the \emph{mutual exclusion guarantee}, 
even though it is not robust against  \( \PSI \). 
To do this, we  encode this  guarantee as an invariant of the lock
library, establishing  the invariant at each transition step of the
operational semantics. 
By contrast, establishing such library-specific properties using the existing techniques is more difficult. 
\polish{We need to be more precise with this last sentence: is this  about 18 and 24?}
This is because  existing techniques do not directly record the library \emph{state}; 
rather, they record full execution traces, making them less amenable for reasoning about such properties.
