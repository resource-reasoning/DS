\section{Introduction}
\ac{Obviously this will be rewritten again and again, but it should give 
an idea of how the paper is going to be structured.}
Modern distributed systems often rely on databases that achieve scalability by weakening the
consistency guarantees of distributed transaction processing. These databases are said
to implement weak consistency models. Such weakly consistent databases allow for faster
transaction processing, but exhibit anomalous behaviours, which do not arise under a database
with a strong consistency guarantee, such as \emph{serialisability}. 

Recently, the research community has made an effort to give formal specifications of weak consistency 
models for transactional distributed databases \cite{ev_transactions,framework-concur,consistency3d,seebelieve,laws,alonetogether}. 
However, the problem of giving the semantics describing the operational behaviour of 
clients interacting with a weakly consistent databases, has been largely neglected. The only 
work that we are aware of in this field is given by \cite{alonetogether}. There the authors 
study the behaviour of functional programs interacting with a relational database, and develop 
a program logic for proving invariants of programs executed by clients of the database. 
\ac{Insert sentence to swiftly kill their paper without being an asshole here.}
\azalea{It needs to be a bit more than a sentence. We need to point out that:
\begin{itemize}
	\item The lack of soundness/completeness result for the operational semantics is a serious shortcoming: it has no relation to existing formal semantics for e.g. SI. 
	The lack of completeness result is particularly damaging as it may prohibit many results allowed by the underlying consistency model. This in turn damages the usability of their logic as many behaviours cannot be verified. 
	
	\item We should also point out that the logic is not so much a logic but a bunch of semantic rules, i.e. no syntactic support. Also that their logic is based on first order logic, and offers no compositionality. Lastly, that it is geared towards databases and as such cannot be adapted for shared memory STMs.
\end{itemize}
}

In this paper we focus on the semantics of clients of distributed key-value 
stores which provide weak consistency guarantees. 
We propose a \emph{coarse-grained} approach to evaluating transactions, 
where transactions are executed by clients in a single, atomic step; furthermore, 
transactions of concurrent clients are executed in an interleaving fashion.
This is In contrast with the work of \cite{alonetogether}, which 
takes a fine-grained approach in which transactions are evaluated one step 
at the time on a local copy of the database, and thus it is possible 
to interleave the execution of transaction; we find this complication to be 
unnecessary, at least in a setting where transactions enjoy \emph{atomic 
visibility}: either none or all the updates of a transaction are made 
visible to another transaction. 

We take a multi-version approach to model the state of a key-value store. 
Each key is mapped to a set of versions. A Version consists of a 
value and the meta-data of the transactions that wrote and read the version. 
At any given instant of time, concurrent clients can observe different versions for the same key.
This approach is necessary to capture the non-serialisable behaviour of 
programs, while still retaining interleaving concurrency and atomic reduction 
of transactions. 

Because we want to model different consistency models, in our semantics 
transactions are executed only prior to passing a particular execution test. For example, 
to constrain a program to only exhibit serialisable behaviours, we require that 
transactions can be executed by a client only if it observes the most 
recent available version for each key. By tweaking the execution test 
of transactions, we tweak the consistency model under which programs 
are executed. In \ref{sec:cmexamples} we give examples of execution tests 
that can be used to model all the consistency models formalised in \cite{framework-concur}.
The notion of execution test is inspired by \cite{seebelieve}. There a notion of \emph{commit test} is introduced 
to determine whether a transaction can be executed safely. However, 
the notion of commit test requires the complete knowledge of 
how the system of the key-value store evolved from its 
initial state (i.e. it requires knowing the total order in which transactions executed in 
the computation); execution tests, on the other hand, only require
knowing the list of versions stored by each key, and the 
information about which version of each key is observed 
by the client executing the transaction.

\azalea{I'm worried that these execution tests are too technical for the intro? If we decide to keep it we should expand the description a little bit more.}

\ac{Paragraph about the thoroughness of the semantics and 
correspondence of our specifications and the declarative 
ones from the CONCUR'15 paper. Paragraph about the logic. 
Here we should stress that clients that execute correctly 
under serialisability, are not necessarily correct under a 
weaker consistency model. There should  be a sentence explaining 
that thoroughness of the semantics is necessary to obtain soundness 
of the logic.}

Contributions of the paper: 
\begin{enumerate}
\item An operational semantics of programs interacting with a key-value store; 
\item Definition of different execution tests for capturing several consistency models,
and a proof that the consistency models captured by the execution tests we propose 
are \emph{sound and complete} (equivalent) with respect to their respective  respective declarative specifications 
given in\cite{framework-concur};
\azalea{Perhaps enumerate them here? e.g. SI, PSI, serialisability, etc.}
\item A proof that the operational semantics is \emph{thorough}: for each of the 
consistency models we formalise, and for any program $\prog$, our semantics captures 
all the behaviours that $\prog$ can display under said consistency model;
\azalea{How is thoroughness different from completeness? I am not sure I understand this. Perhaps this needs clarification?}
\item A separation logic based on our semantics to reason about properties 
of clients interacting with a weakly consistent key-value store.
\end{enumerate}

\ac{Got bored of writing the introduction, in any case it will need to be 
changed a lot in the future.}
%Let us illustrate how our semantics works informally.
%Consider the program $\prog_1$ defined below:
%\[
%\begin{session}
%\begin{array}{@{}c || c@{}}
%\cl_1 : 
%\begin{transaction}
%\pderef{\pvar{a}}{\key{y}};\\
%\pifs{\pvar{a} = 0};\\
%\;\;\; \pmutate{\key{x}}{1};\\
%\}
%\end{transaction}
%&
%\cl_2
%\begin{transaction}
%\pderef{\pvar{a}}{\key{x}};\\
%\pifs{\pvar{a} = 0};\\
%\;\;\; \pmutate{\key{y}}{1};\\
%\}
%\end{transaction}
%\end{array}
%\end{session}
%\]
%There are two concurrent clients, $\cl_1$ and $\cl_2$. Client $\cl_1$ 
%updates the value of key $\key{x}$ to value $1$, provided that 
%it observes value $0$ for key $\key{y}$. Symmetrically, client 
%$\cl_2$ updated the value of $\key{y}$ to $1$ when it observes 
%value $0$ for $\key{x}$. Initially, the (multi-version) key-value store contains only one version 
%with value $0$, for each key. Both the clients $\cl_1$ and $\cl_2$ 
%are equipped with a \emph{view}, which identifies for each key, 
%the version that it will observe for the version 

%Because we reduce transactions in an atomic step, and because we model 
%the behaviour of concurrent clients in an interleaving fashion, we cannot 
%hope to capture non-serialisable behaviours of programs if only the 
%information about the current state of the key-value store were used 
%to evaluate the effects of a transaction. 
