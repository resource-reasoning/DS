\section{Introduction}
Transactions are the \emph{de facto} synchronisation mechanism in modern distributed systems.
To achieve scalability and performance, distributed systems often weaken the transactional consistency guarantees they provide. 
%
%Modern distributed systems often rely on databases that achieve
%scalability and performance by weakening the consistency guarantees of
%distributed transaction processing. 
%
Much work has been done to formalise the semantics of such consistency guarantees, both
declaratively and operationally.
On the declarative side, several \emph{general} formalisms have been proposed, 
such as dependency graphs~\cite{.} and abstract executions~\cite{.}, to provide a unified
framework for formulating different consistency models.  
On the operational side, the semantics of \emph{specific} consistency models have
been captured using reference implementations~\cite{si,PSI,PSI-RA}. 
However, unlike declarative approaches, there has been
little work on \emph{general} operational frameworks for describing a range
of consistency models, and no work on a general operational framework
in which to both verify implementations of distributed databases and 
enable program analysis for clients.

As we discuss in \cref{sec:conclusions}, there are several formalisms for a general operational framework~\cite{sureshConcur,.,.}. 
Kaki \etal propose an operational framework over a global, centralised state for reasoning about clients using a program logic. 
However, although they can model several isolation levels, they cannot capture the well-known
parallel snapshot isolation (PSI) model. 
Moreover, they do not establish the equivalence of their encodings of consistency models 
and the existing declarative definitions in the literature. 
Nagar \etal~\cite{.} propose an operational framework over declarative abstract executions, rather than a concrete centralised state. This framework captures weaker consistency models
such as PSI and has been used to prove robustness results under a given consistency model.  
However, this framework cannot model client sessions.
Finally, Crooks \etal~\cite{.} provide a trace semantics over a global
centralised store, and not an operational semantics. 
Although they prove implementations correct, they do not consider program analysis for clients;
indeed we believe it would be difficult to do so given their choice to
keep track of the entire system.
See related work~\cref{sec:conclusions} for further discussion. 




\ac{
\pg{In above, does Nagar et al.  relate their work to the declarative
  definitions?
Does Crooks et al.?}
Nagar et al. use exactly declarative definitions based on abstract executions.
}
\ac{
\pg{In above, can we really make the claim that Crooks et al. cannot
  do prog analysis as  they need to keep track of the total system?
  MAybe for related work?}
Doing program analysis when you track the total order of system changes 
is difficult, that's the reason why I (and also Nagar and the guys above) switch 
to dependency graphs. Suresh in is POPL paper makes the exact claim that 
it's not clear that Crooks. et al can perform program analysis 
}


We introduce a general operational framework for describing the
behaviour of distributed {atomic} transactions. 
Our model comprises a global, centralised
key-value store (hereafter kv-store) with {\em multi-versioning} and {\em client views}.
%Multi-versioning mandates that we record all versions of each key
%written, together with the meta-data of the transactions that access
%it. This then yields a history of each key, and may be thought as
%projecting the local state of each distributed machine into a global,
%centralised state. 
Through multi-versioning we record all versions of each key, yielding a complete history for each key.
Through client views we allow different clients to observe only a subset of versions in the kv-store, 
enabling different clients to observe different versions of a key and thus capturing the weak behaviours we seek. 
Our work is inspired by the C11 operational semantics in~\cite{viktor'spromises}.

\pg{Above, we can say less about multi-versioning and client views,
  and more in section 2.}

We encode most well-known consistency models in our general framework in a uniform way, including causal consistency (CC), parallel snapshot isolation
(PSI), snapshot isolation (SI) and serialisability (SER). 
We encode these models using kv-stores and views, 
provide a correspondence between our kv-stores and the declarative formalisms, 
and introduce novel proof techniques for demonstrating that our encoding of consistency models 
are equivalent to their existing definitions in declarative frameworks.
%
\pg{For above, is the following too strong: This connection between consistency
  models defined over an operational framework based on a global,
  centralised state  and the traditional 
consistency models defined over a declarative semantics has not been
done before.} 
%

We showcase the applications of our framework for verifying database implementation and client program analysis. 
For the former, we show that the COPS implementation of a 
replicated database satisfies our definition of $\CC$, and that the CLOCK-SI implementation of a sharded database satisfies our definition of $\SI$.  
For the latter, we show the robustness of applications against our consistency models: for example, we prove that a transactional library comprising a single counter is robust against $\PSI$; and we prove that the library with multiple counters is robust against $\SI$, but not $\PSI$.  
To our knowledge, our robustness results are the first to take into account client sessions.
Without sessions, multiple counters are known to be robust against PSI~\cite{.}. 
We verify implementations and analyse clients in the \emph{same} operational
framework. 
By contrast, in existing declarative literature these two tasks are carried out in \emph{different} frameworks: implementations are verified using abstract executions, 
clients are analysed using dependency graphs, and equivalence results are used to move between the two frameworks.



\ac{\pg{In above, has someone shown multiple counters are robust against
  PSI, citation?}
No, but it is immediate to apply the technique from Giovanni and Alexey's paper 
\cite{giovanni_concur16}
to get the robustness of multiple counters under PSI.}

%\cite{...nowwhatshouldthecitationsbeev_transactions,framework-concur,consistency3d,seebelieve,laws,alonetogether}. 







%Let us illustrate how our semantics works informally.
%Consider the program $\prog_1$ defined below:
%\[
%\begin{session}
%\begin{array}{@{}c || c@{}}
%\cl_1 : 
%\begin{transaction}
%\pderef{\pvar{a}}{\key{y}};\\
%\pifs{\pvar{a} = 0};\\
%\;\;\; \pmutate{\key{x}}{1};\\
%\}
%\end{transaction}
%&
%\cl_2
%\begin{transaction}
%\pderef{\pvar{a}}{\key{x}};\\
%\pifs{\pvar{a} = 0};\\
%\;\;\; \pmutate{\key{y}}{1};\\
%\}
%\end{transaction}
%\end{array}
%\end{session}
%\]
%There are two concurrent clients, $\cl_1$ and $\cl_2$. Client $\cl_1$ 
%updates the value of key $\key{x}$ to value $1$, provided that 
%it observes value $0$ for key $\key{y}$. Symmetrically, client 
%$\cl_2$ updated the value of $\key{y}$ to $1$ when it observes 
%value $0$ for $\key{x}$. Initially, the (multi-version) key-value store contains only one version 
%with value $0$, for each key. Both the clients $\cl_1$ and $\cl_2$ 
%are equipped with a \emph{view}, which identifies for each key, 
%the version that it will observe for the version 

%Because we reduce transactions in an atomic step, and because we model 
%the behaviour of concurrent clients in an interleaving fashion, we cannot 
%hope to capture non-serialisable behaviours of programs if only the 
%information about the current state of the key-value store were used 
%to evaluate the effects of a transaction. 
