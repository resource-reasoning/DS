\section{Introduction}

Modern distributed systems often rely on databases that achieve
scalability and performance by weakening the consistency guarantees of
distributed transaction processing.  Much effort has been used to
formalise the semantics of such consistency guarantees, both
declaratively and operationally.  On the declarative side, several
general frameworks have been proposed, such as dependency
graphs~\cite{.} and abstract executions~\cite{.}, to provide a unified
way of formulating many different consistency models.  On the
operational side, the semantics of  specific consistency models have
been captured using reference implementations. However, in contrast
with the declarative approach, there has been
little work on general operational frameworks for describing a range
of consistency models and no work on a general operational framework
in which to both verify implementations of distributed databases and 
provide scable program analysis for clients.

Some work on general operational frameworks has been published. Kaki
{\em et al.}\cite{.} have proposed a operational framework over a
global, centralised state in which to reason about clients using a
program logic. They capture many isolation levels but cannot capture
parallel snapshot isolation (PSI). They provide no link between their
definition of consistency model and the declarative definitions in the
literature. Nagar {\em et al.}\cite{.} have proposed an operational
framework over declarative abstract executions, rather than a concrete
centralised state. This framework captures weaker consistency models
such as PSI and has been used to prove robustness results under a
given consistency model.  This framework cannot model client sessions.
Finally, Crooks {\em et al.} provide a trace semantics over a global
centralised store, not an operational semantics. They prove 
implementations correct but  do not consider program analysis, and
indeed we believe it would be difficult to do so given their choice to
keep track of the total system.
See related work~\ref{.} for further discussion. 





\pg{In above, does Nagar et al.  relate their work to the declarative
  definitions?
Does Crooks et al.?}

\pg{In above, can we really make the claim that Crooks et al. cannot
  do prog analysis as  they need to keep track of the total system?
  MAybe for related work?}



We introduce a general operational framework for describing the
behaviour of distributed {atomic} transactions. It comprises a global, centralised
kv-store with {\em multi-versioning} and partial {\em client views}.
Multi-versioning mandates that we record all versions of each key
written, together with the meta-data of the transactions that access
it. This then yields a history of each key, and may be thought as
projecting the local state of each distributed machine into a global,
centralised state. Client views (or simply views) allow different
clients to observe only a subset of the versions available in the
kv-store: this means that different clients can observe
different versions of a key, thus capturing the weak behaviours
associated we seek. Our work takes inspiration
from the memory model of~\cite{viktor'spromises},  which has been used
to provide a operational  semantics for the  C11 memory model.

\pg{Above, we can say less about multi-versioning and client views,
  and more in section 2.}

We are able to capture most well-known consistency models in a uniform
way, including causal consistency (CC), parallel snapshot isolation
(PSI), snapshot isolation (SI) and serialisability
(SER). We give definitions of consistency models over our kv-stores
and views, provide a correspondence between our kv-stores and the
declarative dependency graphs, and introduce novel proof techniques
for demonstrating that our consistency models are equivalent to the
traditional consistency models based on dependency graphs.
%
\pg{For above, is the following too strong: This connection between consistency
  models defined over an operational framework based on a gloabl,
  centralised state  and the traditional 
consistency models defined over a declarative semantics has not been
done before.} 
%
We demonstrate that the COPS
implementation of a replicated database satisfies our definition of
$\CC$, and the CLOCK-SI implementation of a sharded database satisfies
our definition of $\SI$.  We also reason about clients  to show the
robustness of applications against our consistency models: for
example, we prove the robustness of a single counter against $\PSI$;
and 
we prove the robustness of multiple counters against $\SI$, and show
that they are not robust against $\PSI$.  We believe that these
robustness results are the first to  respect the session order.
Without sessions, multiple counters are known to be robust 
against PSI~\cite{.}. Contrast our approach, which verifies
implementations and analyses clients in the same operational
framework, and the declarative approach,  which tends to use dependency graphs for
program analysis,  abstract executions for verifying
implementations, and equivalence results to move between the two
declarative frameworks.



\pg{In above, has someone shown multiple counters are robust against
  PSI, citation?}

%\cite{...nowwhatshouldthecitationsbeev_transactions,framework-concur,consistency3d,seebelieve,laws,alonetogether}. 







%Let us illustrate how our semantics works informally.
%Consider the program $\prog_1$ defined below:
%\[
%\begin{session}
%\begin{array}{@{}c || c@{}}
%\cl_1 : 
%\begin{transaction}
%\pderef{\pvar{a}}{\key{y}};\\
%\pifs{\pvar{a} = 0};\\
%\;\;\; \pmutate{\key{x}}{1};\\
%\}
%\end{transaction}
%&
%\cl_2
%\begin{transaction}
%\pderef{\pvar{a}}{\key{x}};\\
%\pifs{\pvar{a} = 0};\\
%\;\;\; \pmutate{\key{y}}{1};\\
%\}
%\end{transaction}
%\end{array}
%\end{session}
%\]
%There are two concurrent clients, $\cl_1$ and $\cl_2$. Client $\cl_1$ 
%updates the value of key $\key{x}$ to value $1$, provided that 
%it observes value $0$ for key $\key{y}$. Symmetrically, client 
%$\cl_2$ updated the value of $\key{y}$ to $1$ when it observes 
%value $0$ for $\key{x}$. Initially, the (multi-version) key-value store contains only one version 
%with value $0$, for each key. Both the clients $\cl_1$ and $\cl_2$ 
%are equipped with a \emph{view}, which identifies for each key, 
%the version that it will observe for the version 

%Because we reduce transactions in an atomic step, and because we model 
%the behaviour of concurrent clients in an interleaving fashion, we cannot 
%hope to capture non-serialisable behaviours of programs if only the 
%information about the current state of the key-value store were used 
%to evaluate the effects of a transaction. 
