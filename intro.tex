\section{Introduction}

Modern distributed systems often rely on databases that achieve
scalability and performance by weakening the consistency guarantees of
distributed transaction processing.  Much effort has been used to
formalise the semantics of such consistency guarantees, both
declaratively and operationally.  On the declarative side, several
general frameworks have been proposed, such as dependency
graphs~\cite{.} and abstract executions~\cite{.}, to provide a unified
way of formulating many different consistency models.  On the
operational side, the semantics of  specific consistency models have
been captured using reference implementations. However, in contrast
with the declarative approach, there has been
little work on general operational frameworks for describing a range
of consistency models and no work on a general operational framework
in which to both verify implementations of distributed databases and 
provide scable program analysis for clients.

Some work on general operational frameworks has been published. Kaki
{\em et al.}\cite{.} have proposed a operational framework over a
global, centralised state in which to reason about clients using a
program logic. They capture many isolation levels but cannot capture
parallel snapshot isolation (PSI). They provide no link between their
definition of consistency model and the declarative definitions in the
literature. Nagar {\em et al.}\cite{.} have proposed an operational
framework over declarative abstract executions, rather than a concrete
centralised state. This framework captures weaker consistency models
such as PSI and has been used to prove robustness results under a
given consistency model.  This framework cannot model client sessions.
Finally, Crooks {\em et al.} provide a trace semantics over a global
centralised store, not an operational semantics. They prove 
implementations correct but  do not consider program analysis, and
indeed we believe it would be difficult to do so given their choice to
keep track of the total system.
See related work~\ref{.} for further discussion. 





\pg{In above, does Nagar et al.  relate their work to the declarative
  definitions?
Does Crooks et al.?}

\pg{In above, can we really make the claim that Crooks et al. cannot
  do prog analysis as  they need to keep track of the total system?
  MAybe for related work?}



We introduce a general operational framework for describing the
behaviour of   {\em atomic}
  transactions maniputaing a distributed key-value store
(kv-store). It comprises a global, centralised kv-store with {\em
  multi-versioning} and  partial {\em client views}.  Multi-versioning
mandates that we record all versions of each key written, together
with the meta-data of the transactions that access it. This then
yields a history of each key, and may be thought as projecting the
local state of each distributed machine into a global, centralised
state. Client views (or simply views) allow different clients to
observe only a subset of the versions available in the kv-store:
therefore, different clients can observe different states of the
kv-store, thus allowing for weak behaviours of weak cosistency
models. Our work takes inspiration from the memory model
of~\cite{viktor'spromises} which has been used to provide a promising
semantics for the C11 memory model.





We propose a \emph{coarse-grained} approach to evaluating transactions, 
where transactions are executed by clients in a single, atomic step; furthermore, 
transactions of concurrent clients are executed in an interleaving fashion.
This is in contrast with the work of \cite{alonetogether}, which 
takes a fine-grained approach in which transactions are evaluated one step 
at the time on a local copy of the database, and thus it is possible 
to interleave the execution of transaction; we find this complication to be 
unnecessary, at least in a setting where transactions enjoy \emph{atomic 
visibility}: either none or all the updates of a transaction are made 
visible to another transaction. 

--we can capture most well-known  consistency models in a uniform way

--We present a correspondence between the mathematical structures 
over which our operational specifications, and the declarative
specifications of weak consistency models, are defined. Using 
this correspondence, we formulate proof techniques aimed 
at showing the soundness and completeness of operational specifcations 
with respect to declarative ones.


-----appplications--------

--we can verify implementations is correct with resepct to this
operational semantics: we've shown that COPS satisfies the definition
of CC in our framework,  and CLOCK-SI satisfies the definitions of SI
in our framework


--client reasoning to prove the robustness of applications: 
we prove the robustness of a single counteragainst PSI, and 
at the same time we show that multiple counters are not robust 
against PSI, but are robust against SI. Ours is the first robustness 
results of transactional applications taking into account sessions. 
If sessions are not taken into account, multiple counters are robust 
also against PSI.


thus,....mid-point......



%\cite{...nowwhatshouldthecitationsbeev_transactions,framework-concur,consistency3d,seebelieve,laws,alonetogether}. 






Because we want to model different consistency models, in our semantics 
transactions are executed only prior to passing a particular execution test. For example, 
to constrain a program to only exhibit serialisable behaviours, we require that 
transactions can be executed by a client only if it observes the most 
recent available version for each key. By tweaking the execution test 
of transactions, we tweak the consistency model under which programs 
are executed. In \cref{sec:execution-tests} we give examples of execution tests 
that can be used to model all the consistency models formalised in \cite{framework-concur}.
The notion of execution test is inspired by \cite{seebelieve}. There a notion of \emph{commit test} is introduced 
to determine whether a transaction can be executed safely. However, 
the notion of commit test requires the complete knowledge of 
how the system of the key-value store evolved from its 
initial state (i.e. it requires knowing the total order in which transactions executed in 
the computation); execution tests, on the other hand, only require
knowing the list of versions stored by each key, and the 
information about which version of each key is observed 
by the client executing the transaction.

Contributions of the paper: 
\begin{enumerate}
\item An operational semantics of programs interacting with a key-value store; 
\item Definition of different execution tests for capturing several consistency models,
and a proof that the consistency models captured by the execution tests we propose 
are \emph{sound and complete} (equivalent) with respect to their respective  respective declarative specifications 
given in\cite{framework-concur};
\azalea{Perhaps enumerate them here? e.g. SI, PSI, serialisability, etc.}

\end{enumerate}

%Let us illustrate how our semantics works informally.
%Consider the program $\prog_1$ defined below:
%\[
%\begin{session}
%\begin{array}{@{}c || c@{}}
%\cl_1 : 
%\begin{transaction}
%\pderef{\pvar{a}}{\key{y}};\\
%\pifs{\pvar{a} = 0};\\
%\;\;\; \pmutate{\key{x}}{1};\\
%\}
%\end{transaction}
%&
%\cl_2
%\begin{transaction}
%\pderef{\pvar{a}}{\key{x}};\\
%\pifs{\pvar{a} = 0};\\
%\;\;\; \pmutate{\key{y}}{1};\\
%\}
%\end{transaction}
%\end{array}
%\end{session}
%\]
%There are two concurrent clients, $\cl_1$ and $\cl_2$. Client $\cl_1$ 
%updates the value of key $\key{x}$ to value $1$, provided that 
%it observes value $0$ for key $\key{y}$. Symmetrically, client 
%$\cl_2$ updated the value of $\key{y}$ to $1$ when it observes 
%value $0$ for $\key{x}$. Initially, the (multi-version) key-value store contains only one version 
%with value $0$, for each key. Both the clients $\cl_1$ and $\cl_2$ 
%are equipped with a \emph{view}, which identifies for each key, 
%the version that it will observe for the version 

%Because we reduce transactions in an atomic step, and because we model 
%the behaviour of concurrent clients in an interleaving fashion, we cannot 
%hope to capture non-serialisable behaviours of programs if only the 
%information about the current state of the key-value store were used 
%to evaluate the effects of a transaction. 
